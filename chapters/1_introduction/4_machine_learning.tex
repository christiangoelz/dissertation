Machine Learning emerged in the 1950s to enable computers to learn without being explicitly programmed \cite{Samual1959}. It is defined by computational methods combining fundamental concepts from computer science, statistics, probability and optimization that automatically extract patterns and trends, i.e., \textit{learn} from data \cite{Hastie2009}. The notion of \textit{learning} therein describes the automated inference of general rules based on the observation of examples using algorithms with the goal to solve a certain task or problem \cite{Von_luxburg2011}. Often, in its basic form these tasks involve making predictions based on learned relationships or the extraction of information based on automatically detected patterns and structures from data. Many problems can be formulated by these tasks, and machine learning has found its way into everyday lives not only since the current hype about generative systems. Examples can be found in numerous areas, such as predicting stock prices, personalized advertising based on past search patterns, or autonomous driving \cite{Rudin2014}.\\
Also in science machine learning is increasingly used as a complementary method to classical statistical analysis because of the ability to make predictions as well as to deal with the multidimensional structure and non linearity in real world data sets for drawing inference \cite{Bzdok2018}. Especially in areas where high-dimensional data is prevalent, such as in neuroscience, the use of methods from machine learning offers insight by extracting complex patterns purely data driven \cite{Brunton2019}. In terms of \gls{eeg} this means that machine learning can help identify subtle patterns and nonlinear relationships from the multidimensional complex structure of \gls{eeg} data, allowing for more accurate and efficient analysis of brain recordings. A wide variety of methods are available for this purpose, which can be roughly characterized on the basis of various properties. 

\subsection{Forms of machine learning}
The three main forms of machine learning are supervised, unsupervised, and reinforcement learning which are defined by the type of feedback a machine learning algorithm has access to during learning \cite{Shalev2014}.\\
In supervised machine learning the goal is to learn a generalizable relationship between data and associated information, so-called labels or target. This can then be used to predict the label of new data that not have been used during the process of learning. If the labels are categorical, the prediction task is called classification; for continuous labels, the term is regression.\\
The goal of unsupervised machine learning is to find hidden structure in data without taking into account associated labels. This could be grouping similar data points, i.e. clustering, or uncovering a meaningful low dimensional representation of the data, i.e. dimensionality reduction. This type of learning is also referred to as \textit{knowledge discovery}\cite{Murphy2012}.\\
Reinforcement learning describes the task to learn optimal actions to solve a certain problem by maximizing the reward linked to that action.\\

\begin{figure*}[h]
  \dummyfig{Categories of ML} 
  \caption{Categories of ML}
  \label{fig1:ml_types}
\end{figure*}

In practice however a clear separation is often not possible. As such, dimensionality reduction can also be supervised, i.e. labels are provided to learn a new representation of the data \cite{mcinnes2018umap}. Besides, in semi-supervised learning, for example, the goal is the same as for supervised learning. However the data set used to learn the relationship contains both, labeled and unlabeled examples and the hope is to build a stronger representation by providing more information in form of data \cite{Burkov2019}. \\
In addition traditional machine learning is often contrasted to deep learning methods involving the use of artificial neural networks which are composed of many layers of interconnected nodes often used in an end to end fashion in which features are extracted within the network. Usually they require huge amount of data and computational power. In the context of this thesis the tasks considered involve the processing of a \gls{eeg} from experiments with mid to small sample sizes with the goal to learn meaningful patterns and relationships in data. The most commonly used forms in this contexts are supervised and unsupervised learning focusing traditional machine learning. For this reason these forms will be the focus in the following chapters.\\

\subsection{Applications to electroencephalography}
Traditionally, machine learning has been the core building block for the development of intelligent systems that can automate tasks or enhance and assist humans in performing their tasks. In the medical field the hope is to develop intelligent medical systems to inform clinical theory and support clinical decision making, i.e. assist in diagnosis, and risk management by predicting health status or forecasting of treatment responses \cite{Woo2017}. In this context, supervised learning is often used to identify markers from \gls{eeg} by identifying signal features that are predictive of a particular disease or health condition, which is highly important in terms of promoting a healthy aging trajectory \cite{Babiloni_AlzCons2021,Mei2021}. An application is the estimation of biological age based on regression models trained on the basis on neural data, e.g. \gls{eeg}, recorded in large population studies \cite{Engemann2022}. Using data of an individual person, a regression model can predict the age of that person. If the brain appears older than it would chronologically, this can be an early indication of an unfavorable state of health \cite{Gonneaud2021}.\\
Another in the context of aging highly relevant application is the development of devices with the goal to assist, augment or enhance humans capabilities such as \glspl{bci}. In \glspl{bci}, neural activity is decoded, using classification to generate control commands for various external devices such as computers or prosthetic limbs \cite{Saha2021, Anumanchipalli2019}. Decoding hereby refers to learning a classification or regression model that is capable of predicting behavioral outcomes or cognitive states based on neural data, e.g. \gls{eeg}.\\
Beyond the application in \glspl{bci}, decoding techniques are widely used in neuroscientific research to gain insights into the neural mechanisms underlying perception, cognition, and behavior. This type of analysis is often referred to as \gls{mvpa} because its goal is to detect multivariate patterns, e.g., a set of voxels in \gls{fmri} or an electrical pattern at a given time in \gls{eeg}, associated with an experimental condition \cite{Holdgraf2017}.  While the use has a long history in the field of \gls{fmri} analysis, it has only become more widespread in the field of \gls{eeg} in recent years.  Therefore, decoding approaches to understand age-related reorganization are mostly limited to fMRI studies. A common approach is to quantify dedifferentiation, i.e. the loss of neural specificity, at the individual level. Since dedifferentiation by definition results in more similar brain activation patterns for different tasks or stimuli, poorer performance of classifiers trained to discriminate between them based on neural recordings is indicative of a less distinctive neural representation \cite{Koen2019, Park2010}. \\ 
Furthermore, the classification of group membership or group level regression can provide information about interesting relationships and their generalizability. Particularly for \gls{eeg} markers representing functional network characteristics can reveal insightful findings about the relationship to age-related changes \cite{Petti2016}.\\
In addition to the application of supervised learning algorithms, unsupervised learning algorithms have long been used in neuroscience. Unsupervised methods are often used as a preprocessing step to reduce the complexity of \gls{eeg} data or provide a framework for statistical source imaging but can also provide interesting insights into the structure of data sets. For example dimensionality reduction algorithms can provide insights into high-dimensional data by providing a possibility to visualize high dimensional patterns of \gls{eeg} data \cite{Kottlarz2020, Banville2021}. This can be used to study the temporal structure of \gls{eeg} signals in terms of the dynamic of brain networks with aging \cite{Brunton2016, vieluf2018age}. \\
In summary, the use of machine learning is very diverse and ranges from engineering applications to scientific knowledge discovery. Especially in the latter case, it offers the advantage of automated extraction of patterns from highly complex data that can contribute to the study of age-related changes. While decoding approaches are particularly interesting for tracking age-related changes in the organization of neural systems, such as the level of differentiation, group analysis could provide new insights into datasets. The combination with unsupervised learning algorithms could be particularly beneficial and used for the visualization of high-dimensional data.

\subsubsection{State of the art approaches}
Depending on the learning objective or task, the procedure for the application of machine learning algorithms differs. However, some aspects should be considered especially for \gls{eeg} data, since one typically deals with high-dimensional data, i.e. time series of multiple sensors with auto-correlative structure and a low signal to noise ration to avoid overfitting of the machine learning model. In this case, the model overweights properties of the data used to learn, such as noise, and is thus not suitable to generalize to unknown data. While novel applications highlight the use of deep neural networks capable of learning on the basis of raw data, i.e., end to end, their advantage comes into play with large labeled data resources, which are often expensive to acquire in the case of \gls{eeg} \cite{Banville2021}. Especially for comparatively smaller data sets, traditional learning approaches can be more efficient with good performance and promise better interpretability \cite{Gemein2020}. Due to the low signal to noise ratio, \gls{eeg} data are typically preprocessed and parameters, so called features, are extracted that are believed to be related to the problem being learned. Typical feature include all common \gls{eeg} parameters of time, frequency, as well as time-frequency and information theoretical parameters which are extracted for each sensor. Typical features include all common \gls{eeg} parameters of time, frequency, and time-frequency as well as information-theoretic parameters (see \gls.

Multicolinearity as a problem 
Prior Knowledge 
-> Decomposition techniques in absence of MRI