The following chapters include an introduction to machine learning along with basic formalism and terminology. Next an overview of how machine learning is used in the field of neuroscience will be given by highlighting relevant literature. Subsequently, the changes in the aging brain that are relevant for this thesis will be presented as well as the application of methods used in this field. The goal is to highlight application areas and methodologies that are relevant for the following research. 

\subsection{Machine learning}
\label{subsec:ML}
Machine Learning emerged in the 1950s as a subbranch of \gls{ai} to enable computers to learn without being explicitly programmed \cite{Samual1959}. It is defined by algorithms that automatically extract patterns and trends or \textit{learn} from data \cite{Hastie2009}. The notion of \textit{learning} therein describes the process of acquiring the ability to generalize these trends and patterns to unknown data not used during this process. The goal of machine learning is therefore to extract generalizable patterns based on examples or so-called training data that allow new data to be classified or predictions to be made. The data may contain few or multiple properties, so-called features, and may be multidimensional with variable sources for example sensor recordings or pixel values.\\ 
Besides solving computational problems algorithms from machine learning offer additional value for scientific inquiry including the possibility for the automatic analysis of complex multidimensional data \cite{Brunton2019,Breiman2001}. In this approach, rather than assuming that data is generated by an underlying stochastic model as in classical statistical modelling the mechanisms are treated as unknown which may overcome inaccuracies in the analysis \cite{Breiman2001}. Furthermore, by extracting generalizable principles from the complex interaction of features it offers additional values to traditional hypothesis-driven approaches \cite{Vu1601,Bzdok2017}. \medskip\\
Machine learning can be subdivided into three categories, supervised, unsupervised and reinforcement learning. In supervised machine learning the goal is to learn a function representing the relationship between data and associated information or descriptions, so-called labels or targets. This function also called model can be thought of a mathematical description of the real world \cite{Brunton2019}, which can than be used to predict the label of new data that not have been used during the process of learning. If the labels are categorical, it is called classification; for continuous labels, the term is regression. The goal of unsupervised machine learning is to find hidden structure in data without taking into account associated labels. This could be grouping similar data points, i.e. clustering, or uncovering a meaningful low dimensional representation of the data, i.e. dimensionality reduction. 
A formal description of supervised and unsupervised learning can be found in \cite{Brunton_kutz_2019} and \cite{Murphy2012}:\\
Given an open bounded set \(\mathcal{D}\) of dimension \(n\) so that
\begin{equation}
    \mathcal{D}\subset\mathbb{R}^{n},
\end{equation}
as well as the subset \(\mathcal{D}^{'}\) 
\begin{equation}
    \mathcal{D}^{'}\subset\mathcal{D}^{n}
\end{equation}
the goal is to build a model from data \(\mathcal{D}^{'}\) that can generalize to \(\mathcal{D}\). As written above, in supervised learning this is to learn a mapping function \(f\) from inputs \(x\) (features) to outputs \(y\) (labels), i.e. \(y = f(x)\), based on the subset, or training data
\begin{equation}
    \mathcal{D}^{'}=\{(x_j, y_j), j \in Z := \{1,2,...m\}\}. 
\end{equation}
For classification \(y_j\) is a categorical finite set \(y_j \in \{1,2...C\}\) and for regression a real valued scalar \(y_j \in \mathbb R^{n}\). Each element \(x_j \in \mathbb R^{n}\) is a description of a sample and called feature vector.
In the unsupervised case, however, only inputs are given and 
\begin{equation}
    \mathcal{D}^{'}=\{x_j, j \in Z := \{1,2,...m\}\}. 
\end{equation}
Rather than a specific label in reinforcement learning the goal is to learn optimal actions to solve a certain problem by maximizing the reward linked to that action. However this type of machine learning is less commonly used in scientific enquiry and therefore not further described here.

\subsubsection{Applications in Neuroscience}
Both fields, research on \gls{ai} and neuroscience, are strongly interconnected as information processing in the brain serves as role model for the ultimate goal in \gls{ai} research, creating an artificial general intelligence system matches or even surpass human intelligence \cite{Macpherson2021}. This led, for example, to the development of artificial neural networks, a class of machine learning algorithms that underlie modern advances in the field of \gls{ai} \cite{Cox2014}. Other examples are so called \glspl{cnn}, which are used in computer vision and inspired by the architecture of the visual ventral stream or \glspl{rnn} mimicking the functioning of working memory \cite{Macpherson2021, Fukushima1982, Yin2020}. On the other side, \glspl{cnn} and \glspl{rnn} are used to understand functional and organizational properties of the visual system \cite{Yamins2014} or working memory \cite{Kim2021} which highlights the bilateral relationship between machine learning and neuroscience and so its use in neuroscience is widespread. The goals incorporate not only solving practical problems such as advancements in biomedical engineering or data processing, but also gaining insights and drawing conclusions by testing hypotheses and developing new theories.\\
Traditionally, machine learning has been the core building block for the development of intelligent systems that can automate tasks or enhance and assist humans in performing their tasks. Examples of automation in the field of neuroscience can be found, among others, in relation to the processing of neuroscientific data addressing low reproducibility and subjectivity. \citeauthor{Jas2017} \cite{Jas2017} use unsupervised machine learning to automate data prepossessing, i.e. rejecting and interpolating bad data segments, in the analysis of data from \gls{eeg} or \gls{meg}. In addition, machine learning is increasingly used for electrical source imaging to solve the inverse problem, i.e. finding neural sources that give rise to the recorded \gls{eeg} activity \cite{Cui2019,Hecker2021}. Other applications involve classification to automatically segment images from \gls{mri}, e.g. in grey or white matter, or the automatic detection and quantification of cell activation in calcium imaging \cite{Akkus2017}. In medical settings furthermore machine learning can be applied with the goal to support clinical decision making, i.e. assist in diagnosis, risk assessment by predicting health status or forecasting of treatment responses \cite{Woo2017}. Examples include classification to support the diagnosis of Alzheimer's disease based on EEG \cite{Gallego-Jutgl√†2015} or MRI \cite{Vemuri2008} data as well as the automated identification of lesions in radiographic brain images \cite{Zhou208} or the detection of epileptic seizures based on EEG data \cite{Vandecasteele2020}. Beyond that, machine learning is often used in engineering devices with the goal to assist, augment or enhance humans capabilities such as \glspl{bci}. In \glspl{bci}, neural activity is decoded using classification to generate control commands for various external devices such as computers or prosthetic limbs \cite{Saha2021, Anumanchipalli2019}. In this context unsupervised methods, i.e. dimensionality reduction, often are used to deal with the high dimensionality and variability of measured neural activity \cite{Brunton2019}.\\
While the examples described so far have focused on solving specific problems, machine learning algorithms provide mechanistic insights into the information structure of data and the generalizability of hypotheses \cite{Hastie2009}. Especially in areas where high-dimensional data is prevalent, such as in neuroscience, the use of supervised as well as unsupervised machine learning offers insight by extracting complex patterns purely data driven \cite{Bzdok2017}. Dimensionality reduction, for example, makes it possible to describe the structure of high-dimensional data with fewer properties \cite{Cunningham2014}. Two common methods in the analysis of neuroscientific data are \gls{pca} or \gls{ica} which are used to uncover meaningful patterns in the data, such as brain networks or brain states underlying behavior \cite{Friston2011, Varoquaux2010}. In addition, with \gls{dmd}, \citeauthor{Brunton2016} \cite{Brunton2016} apply for the first time a method to \gls{ecog} that allows to map both the spatial and temporal structure of the network structure of sleep spindels and arm movements.
Clustering etc... 


% Supervised: Engineering applications, within fMRI research. Unsupervised: Clustering and grouping as well as dimensionality reduction is a big part. 

% SUBSUBSECTION {ABGRENZUNBG ZU KLASSISCH STATISTISCHEN VERFAHREN????}

% - Clinical: identify disease, develop bio-markers, characterize patients, epilepsy detection/prediction
% - Basic: Understand working principle of processing, e.g. visual system, working memory
% - Cognitive: Identify brain states and study brain behavior interaction

% Summary: 
% - Solving engineering problems as well as understanding brain processing 
% - Investigate high dimensional representations with classification/regression/model selection 
% - Uncover underlying processes with dimensionality reduction


% \subsection{Age related reorganization of the brain}
% \label{subsec:Aging}
% In general aging is an ongoing process that can be detected at multiple interacting biological systems operating on several spatial and temporal scales contributing to the complexity of the phenomenon \cite{Mooney2016}. The most prominent consequences of this are declines in cognitive and sensorimotor abilities challenging the daily life of older adults.
% Age related reorganization processes are detectable at the whole body. This is underpinned by multiple interacting biological systems operating on several spatial and temporal scales contributing to the complexity of the phenomenon \cite{Mooney2016}. At the behavioral level these processes are noticeable in changes in cognitive, motor and sensory functioning [QUELLE]. Aging is one of the biggest risk factors for neurodegenerative diseases such as dementia, including Alzheimer's disease, as well as Parkinson's disease making the brain as one of the target systems to study. Patterns of reorganization of the brain are highly individual as they are subject to genetic and environmental influences [QUELLEN]. At the same time, however, overarching, generalizable patterns can be detected [QUELLE]\\
% On a structural level aging has been associated with a reduction in gray matter with an onset early in life 

% \subsubsection{Machine Learning usages in aging neuroscience}
% TEXT