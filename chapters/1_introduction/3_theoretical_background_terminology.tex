The following chapters include an introduction to machine learning along with basic formalism and terminology. Next an overview of how machine learning is used in the field of neuroscience will be given by highlighting relevant literature. Subsequently, the changes in the aging brain that are relevant for this thesis will be presented as well as the application of methods used in this field. The goal is to highlight application areas and methodologies that are relevant for the following research. 

\subsection{Machine learning}
\label{subsec:ML}
Machine Learning emerged in the 1950s as a subbranch of \gls{ai} to enable computers to learn without being explicitly programmed \cite{Samual1959}. It is defined by algorithms that automatically extract patterns and trends or \textit{learn} from data \cite{Hastie2009}. The notion of \textit{learning} therein describes the process of acquiring the ability to generalize these trends and patterns to unknown data not used during this process. The goal of machine learning is therefore to extract generalizable patterns based on examples or so-called training data that allow new data to be classified or predictions to be made. The data may contain few or multiple properties, so-called features, and may be multidimensional with variable sources for example sensor recordings or pixel values.\\ 
Besides solving computational problems algorithms from machine learning offer additional value for scientific inquiry including the possibility for the automatic analysis of complex multidimensional data \cite{Brunton2019,Breiman2001}. In this approach, rather than assuming that data is generated by an underlying stochastic model as in classical statistical modelling the mechanisms are treated as unknown which may overcome inaccuracies in the analysis \cite{Breiman2001}. Furthermore, by extracting generalizable principles from the complex interaction of features it offers additional values to traditional hypothesis-driven approaches \cite{Vu1601,Bzdok2017}. \medskip\\
Machine learning can be subdivided into three categories, supervised, unsupervised and reinforcement learning (see Figure \ref{fig1:ml_types}). In supervised machine learning the goal is to learn a function representing the relationship between data and associated information or descriptions, so-called labels or targets. This function also called model can be thought of a mathematical description of the real world \cite{Brunton2019}, which can than be used to predict the label of new data that not have been used during the process of learning. If the labels are categorical, it is called classification; for continuous labels, the term is regression. The goal of unsupervised machine learning is to find hidden structure in data without taking into account associated labels. This could be grouping similar data points, i.e. clustering, or uncovering a meaningful low dimensional representation of the data, i.e. dimensionality reduction. 
A formal description of supervised and unsupervised learning can be found in \cite{Brunton_kutz_2019} and \cite{Murphy2012}:\\
Given an open bounded set \(\mathcal{D}\) of dimension \(n\) so that
\begin{equation}
    \mathcal{D}\subset\mathbb{R}^{n},
\end{equation}
as well as the subset \(\mathcal{D}^{'}\) 
\begin{equation}
    \mathcal{D}^{'}\subset\mathcal{D}^{n}
\end{equation}
the goal is to build a model from data \(\mathcal{D}^{'}\) that can generalize to \(\mathcal{D}\). As written above, in supervised learning this is to learn a mapping function \(f\) from inputs \(x\) (features) to outputs \(y\) (labels), i.e. \(y = f(x)\), based on the subset, or training data
\begin{equation}
    \mathcal{D}^{'}=\{(x_j, y_j), j \in Z := \{1,2,...m\}\}. 
\end{equation}
For classification \(y_j\) is a categorical finite set \(y_j \in \{1,2...C\}\) and for regression a real valued scalar \(y_j \in \mathbb R^{n}\). Each element \(x_j \in \mathbb R^{n}\) is a description of a sample and called feature vector.
In the unsupervised case, however, only inputs are given and 
\begin{equation}
    \mathcal{D}^{'}=\{x_j, j \in Z := \{1,2,...m\}\}. 
\end{equation}
Rather than a specific label in reinforcement learning the goal is to learn optimal actions to solve a certain problem by maximizing the reward linked to that action. However this type of machine learning is less commonly used in scientific enquiry and therefore not further described here.\\
\\
\begin{figure*}[h]
  \dummyfig{Categories of ML} 
  \caption{Categories of ML}
  \label{fig1:ml_types}
\end{figure*}

\subsubsection{Applications in Neuroscience}
Both fields, research on \gls{ai} and neuroscience, are strongly interconnected as information processing in the brain serves as role model for the ultimate goal in \gls{ai} research, creating an artificial general intelligence system that matches or even surpass human intelligence \cite{Macpherson2021}. This led, for example, to the development of artificial neural networks, a class of machine learning algorithms that underlie modern advances in the field of \gls{ai} \cite{Cox2014}. Other examples are so called \glspl{cnn}, which are used in computer vision and inspired by the architecture of the visual ventral stream or \glspl{rnn} mimicking the functioning of working memory \cite{Macpherson2021, Fukushima1982, Yin2020}. On the other side, \glspl{cnn} and \glspl{rnn} are used to understand functional and organizational properties of the visual system \cite{Yamins2014} or working memory \cite{Kim2021} which highlights the bilateral relationship between machine learning and neuroscience and so its use in neuroscience is widespread. The goals incorporate not only solving practical problems in biomedical engineering or data processing, but also gaining insights and drawing conclusions by testing hypotheses and developing new theories.\\
Traditionally, machine learning has been the core building block for the development of intelligent systems that can automate tasks or enhance and assist humans in performing their tasks. Examples of automation in the field of neuroscience can be found, among others, in relation to the processing of neuroscientific data addressing low reproducibility and subjectivity. \citeauthor{Jas2017} \cite{Jas2017} use unsupervised machine learning to automate data prepossessing, i.e. rejecting and interpolating bad data segments, in the analysis of data from \gls{eeg} or \gls{meg}. In addition, machine learning is increasingly used for electrical source imaging to solve the inverse problem, i.e. finding neural sources that give rise to the recorded \gls{eeg} activity \cite{Cui2019,Hecker2021}. Other applications involve classification to automatically segment images from \gls{mri}, e.g. in grey or white matter, or the automatic detection and quantification of cell activation in calcium imaging \cite{Akkus2017}. In medical settings furthermore machine learning can be applied with the goal to support clinical decision making, i.e. assist in diagnosis, risk assessment by predicting health status or forecasting of treatment responses \cite{Woo2017}. Examples include classification to support the diagnosis of Alzheimer's disease based on EEG \cite{Gallego-Jutgl√†2015} or \gls{mri} \cite{Vemuri2008} data as well as the automated identification of lesions in radiographic brain images \cite{Zhou208} or the detection of epileptic seizures based on EEG data \cite{Vandecasteele2020}. Beyond that, machine learning is often used in developing devices with the goal to assist, augment or enhance humans capabilities such as \glspl{bci}. In \glspl{bci}, neural activity is decoded, using classification to generate control commands for various external devices such as computers or prosthetic limbs \cite{Saha2021, Anumanchipalli2019}. In this context unsupervised methods, i.e. dimensionality reduction, often are used to deal with the high dimensionality and variability of measured neural activity \cite{Brunton2019}.\\
While the examples described so far have focused on solving specific problems, machine learning algorithms provide mechanistic insights into the information structure of data and the generalizability of hypotheses \cite{Hastie2009}. Especially in areas where high-dimensional data is prevalent, such as in neuroscience, the use of supervised as well as unsupervised machine learning offers insight by extracting complex patterns purely data driven \cite{Bzdok2017}. Dimensionality reduction, for example, makes it possible to describe the structure of high-dimensional data with fewer properties \cite{Cunningham2014}. Two common methods in the analysis of neuroscientific data are \gls{pca} or \gls{ica} which are used to uncover meaningful patterns in the data. Especially \gls{ica} is increasingly applied to uncover brain networks based on \gls{fmri} data \cite{Varoquaux2010} or to uncover the statistical sources in \gls{eeg} which can be used to infer components of noise but as well on brain processes during behavior \cite{Strophal2018}.  In addition, with \gls{dmd}, \citeauthor{Brunton2016} \cite{Brunton2016} apply a method to \gls{ecog} that allows to map both the spatial and temporal structure of sleep spindle networks as well as task related brain networks involved in movements. Besides dimensionality reduction, clustering is used to identify subgroups at different levels ranging from molecules to participant groups giving rise to new testable hypothesis \cite{Vu1601}. By applying a nonlinear dimensionality reduction technique called \gls{umap} and clustering to data of extracellular waveforms recorded in the premotor cortex of macaques, \citeauthor{Lee2021} \cite{Lee2021} were able to identify subgroups of neurons with previously unknown diversity in terms of dynamics and laminar distribution. Furthermore, in another study analysing \gls{fmri} during different cognitive tasks, \citeauthor{Hawco2021} \cite{Hawco2021} assessed the variability structure of brain activation patterns and identified a spectrum of participants brain activation patterns that coincides with task performance. These results were only possible using advanced methods from machine learning. Besides unsupervised approaches, supervised approaches are being used to map brain function to external variables, such as group membership, behavior or stimuli, with the ultimate goal to identify predictive variables or features \cite{Glaser2019}. Under this objective classification of group membership, inferences can be made about the underlying mechanisms of the phenomenon under study. This is often of interest to inform clinical theory in the development of novel biomarkers, for example in autism \cite{Deshpande2013} or Alzheimer's disease \cite{Farina2020}, as well as in basic neuroscience. In this context, regression is used to predict the neural response to an external variable, such as a particular stimulus, to create a so-called encoding model, which can be used to test and compare brain computational theories \cite{Kriegskorte2019, Naselaris2011}. \citeauthor{Benjamin2018} \cite{Benjamin2018}, for example, show the superiority of using modern machine learning in predicting spike rates based on behavioral measurements. Contrary, decoding models are created with the goal to predict external variables from neural activity providing insights in the information content of neural measurements. This type of analysis is often referred to as \gls{mvpa} because its goal is to detect multivariate patterns, e.g., a set of voxels in fMRI or an electrical pattern at a given time in EEG, associated with an experimental condition based on goodness of classification or regression \cite{Holdgraf2017}. For example, neural dynamics in visual object perception \cite{Cauchoix2014} or working memory \cite{Bae2018} have been studied using decoding approaches applied to \gls{eeg} recordings. Decoding was also linked to another variable, such as group membership \cite{Csizmadia2021, Bae2020} or symptom scores \cite{Coutanche2011} , to reveal interesting interrelationships with neural representations of the condition under study.\\
In summary, the application of machine learning in neuroscience is diverse. In addition to a close theoretical integration of the two fields, machine learning offers solutions to engineering problems in supporting and augmenting human performance as well as in data processing. In basic sciences, it is used to extract patterns from highly complex data and gain insights into the predictive power of variables. This can contribute to the verification and formation of new hypotheses.

% Summary: 
% - Solving engineering problems as well as understanding brain processing 
% - Investigate high dimensional representations with classification/regression/model selection 
% - Uncover underlying processes with dimensionality reduction

% SUBSUBSECTION {ABGRENZUNBG ZU KLASSISCH STATISTISCHEN VERFAHREN????}

% \subsection{Age related reorganization of the brain}
% \label{subsec:Aging}
% In general aging is an ongoing process that can be detected at multiple interacting biological systems operating on several spatial and temporal scales contributing to the complexity of the phenomenon \cite{Mooney2016}. The most prominent consequences of this are declines in cognitive and sensorimotor abilities challenging the daily life of older adults.
% Age related reorganization processes are detectable at the whole body. This is underpinned by multiple interacting biological systems operating on several spatial and temporal scales contributing to the complexity of the phenomenon \cite{Mooney2016}. At the behavioral level these processes are noticeable in changes in cognitive, motor and sensory functioning [QUELLE]. Aging is one of the biggest risk factors for neurodegenerative diseases such as dementia, including Alzheimer's disease, as well as Parkinson's disease making the brain as one of the target systems to study. Patterns of reorganization of the brain are highly individual as they are subject to genetic and environmental influences [QUELLEN]. At the same time, however, overarching, generalizable patterns can be detected [QUELLE]\\
% On a structural level aging has been associated with a reduction in gray matter with an onset early in life 

% \subsubsection{Machine Learning usages in aging neuroscience}
% TEXT