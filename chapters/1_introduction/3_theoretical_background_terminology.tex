The following chapters include an introduction to aging with a focus on aging of the brain. It should be noted that this does not include the entire field of aging research, but rather highlights key concepts that are relevant to this work. Next Machine learning will be introduced along with basic formalism and terminology. Subsequently an overview of how machine learning is used in the field of neuroscience focusing aging research will be given by highlighting relevant literature. The goal is to highlight application areas and methodologies that are relevant for the following research.

\subsection{Aging}
Biologically aging can be broadly characterized as "the time-dependent functional decline that affects most living organisms" \cite{López-Otín2013}. It can be observed in the reorganization of multiple interacting physiological systems operating at different spatial and temporal scales \cite{Mooney2016}. The underlying patterns of reorganization within and between these systems are highly individual, as they are subject to internal (e.g., genetic, cellular, molecular) as well as external (e.g., environmental, and lifestyle) influences \cite{Smith2020, Mooney2016, Cohen2022}. At the same time, however, overarching, generalizable patterns can be identified \cite{Salthouse2019}. At the behavioral level, the most recognizable consequences of aging are declines in cognitive, sensory, and motor abilities that challenge the daily lives of older adults \cite{Li2002}. Understanding brain reorganization is of particular interest because of its critical role in these declines as well as in the functioning of the body in general. Moreover, aging is one of the major risk factors for neurodegenerative diseases \cite{Hou2019}.

\subsubsection{The aging brain}
Brain aging involves neuroanatomical as well as neurochemical changes. Changes in the structure of the brain include, among others, atrophy of the gray and white matter as well as enlargement of cerebral ventricles \cite{Fjell2010}. Moreover, the efficiency of neuromodulation declines, i.e. changes of various neurotransmitter systems. Besides this, the study of the functional properties of the brain and their relationship to behavioural changes is of great interest. In neuroimaging studies, both under-activation and over-activation of brain areas have been reported in older adults compared to younger adults during performance in various tasks with sensory, cognitive as well as motor demands \cite{Reuter-Lorenz2010, Sala-Llonch2015}. \citeauthor{Courtney2021} \cite{Courtney2021} highlights the role of dynamics of neural activity to understand age related changes of the brain and their relation to behavior. The authors summarize that brain activity in response to a stimulus is often slower or delayed. Moreover, the frequency distribution of neural oscillatory activity changes with respect to a slowing of the main rhythms and altered temporal dynamics which is interpreted as a change in neural communication \cite{Courtney2021}.\\ 
By emphasising neural communication and information flow, rather than viewing the brain as functionally separate, it can be conceptualised as a complex system whose functional units, i.e. neurons, areas and subsystems, are interconnected both structurally and functionally \cite{Friston2011,Deery2023}. In this concept, functional connectivity reflects coherent patterns of activation within and between these units. Several distinct but interconnected functional networks\footnote{These networks mainly include the sensorimotor, visual, attention, control, salience, and \gls{dmn}, which have been named based on the functional systems they are thought to support \cite{Uddin2019}.} were identified. The dynamic interplay between and within these networks is characterized by segregation and integration at different levels, characterizing the flow of information in the brain \cite{Sporns2013}. Older adults information flow tend be less efficient and is characterized by lower within network connectivity and higher between network connectivity associated with a less segregated, less modular and more integrated brain network organization \cite{Sala-Llonch2015,Deery2023, Betzel2014}. However, studies on sensorimotor and visual networks seem to be very heterogeneous, which could indicate very individual reorganization patterns \cite{Deery2023}.

\subsubsection{Dedifferentiation and compensation}
Changes in activation patterns and functional network organization, can be attributed to dedifferentiation and compensation \cite{Grady2012}. Dedifferentiation refers to the loss of neural specialisation or reduced distinctiveness of neural responses resulting in a diffuse, non specific recruitment of brain resources \cite{Koen2019}. Historically, the term originates from behavioral research in which an increased correlation of performance between sensory and cognitive and sensorimotor domains was reported in older adults \cite{Baltes1997,Li2002}. In order to explain this behavioral dedifferentiation Li and colleagues \cite{Li2001, Li2002} provided a computational model. According to this model, deficient dopaminergic modulation observed in older adults may affect the responsiveness of cortical neurons, leading to higher levels of neuronal noise and ultimately to less differentiated, more diffuse neuronal activation patterns in response to different stimuli \cite{Li2001,Li2002}. In several simulations, the authors demonstrated that the proposed model can explain not only behavioral co-variation, but also several other phenomena, such as the decrease in average performance or the increase in behavioural intra- and inter-person variability \cite{Li2000,Li2002}. In addition, the proposition of a less distinctive, less specific neuronal activation in response to stimuli could be confirmed in neuroimaging studies showing that the neural responses to various visual, cognitive and motor stimuli are less specific in older compared to young adults \cite{Tucker2019, Koen2019,Carb2011}. The changes described above are consistent with this view. The functional networks is less segmented and modular, and less specialised in terms of dedifferentiation \cite{Koen2019, Sala-Llonch2015}.\\
\citeauthor{Fornito2015}\cite{Fornito2015} describe dedifferentiation as a fundamental maladaptive mechanism of brain networks that requires compensation. Compensation refers to the ability to recruit additional brain resources to compensate for decline and functional loss in order to maintain cognitive and behavioural functioning \cite{Reuter-Lorenz2010, Grady2012}. Here, the \gls{crunch} hypothesizes that compensatory activity changes as a function of task demands. Moreover, compensation often occurs in a specific pattern of under-activation of posterior areas and prefrontal over-activation, known as \gls{pasa} \cite{Davis2007}. Another often reported pattern is the more bilateral recruitment and loss of hemispheric specialisation, known as \gls{harold} \cite{Cabeza2002}.\\
It is important to note that dedifferentiation and compensation are by no means static and predetermined, but are based on a complex interplay of genetic and lifestyle factors \cite{Smith2020,Koen2019,Douw2014}. KOEN Lifetime experience hypothesis... Besides that the concept of cognitive reserve which describes the ....  

The concepts of cognitive reserve and maintenance are worth mentioning here. [EXPLAIN IN ONE SENTENCE]. 




Besides genetic, environmental influences including lifestyle factors seem to play a role \cite{Smith2020} and several beneficial lifestyle factors such as education \cite{Chan2021} or cardiovascular fitness level \cite{Douw2014} have been identified.\\
In summary, healthy aging is associated with changes at the cognitive, sensory, as well as motor levels. This is associated with structural and functional changes of the brain, especially a reorganization of brain networks. Besides overarching patterns, the changes are highly individual.

\subsection{Machine learning}
\label{subsec:ML}
Machine Learning emerged in the 1950s as a subbranch of \gls{ai} to enable computers to learn without being explicitly programmed \cite{Samual1959}. It is defined by algorithms that automatically extract patterns and trends or \textit{learn} from data \cite{Hastie2009}. The notion of \textit{learning} therein describes the process of acquiring the ability to generalize these trends and patterns to unknown data not used during this process. The goal of machine learning is therefore to extract generalizable principles based on examples or so-called training data that allow new data, so called testing data, to be classified or predictions to be made. The data may contain few or multiple properties, so-called features, and may be multidimensional with variable sources for example sensor recordings or pixel values.\\ 
Machine learning can be subdivided into three categories, supervised, unsupervised and reinforcement learning (see Figure \ref{fig1:ml_types}). In supervised machine learning the goal is to learn a function representing the relationship between data and associated information or descriptions, so-called labels or targets. This function also called model can be thought of a mathematical description of the real world \cite{Brunton2019}, which can than be used to predict the label of new data that not have been used during the process of learning. If the labels are categorical, it is called classification; for continuous labels, the term is regression. The goal of unsupervised machine learning is to find hidden structure in data without taking into account associated labels. This could be grouping similar data points, i.e. clustering, or uncovering a meaningful low dimensional representation of the data, i.e. dimensionality reduction. 
A formal description of supervised and unsupervised learning can be found in \cite{Brunton_kutz_2019} and \cite{Murphy2012}:\\
Given an open bounded set \(\mathcal{D}\) of dimension \(n\) so that
\begin{equation}
    \mathcal{D}\subset\mathbb{R}^{n},
\end{equation}
as well as the subset \(\mathcal{D}^{'}\) 
\begin{equation}
    \mathcal{D}^{'}\subset\mathcal{D}^{n}
\end{equation}
the goal is to build a model from data \(\mathcal{D}^{'}\) that can generalize to \(\mathcal{D}\). As written above, in supervised learning this is to learn a mapping function \(f\) from inputs \(x\) (features) to outputs \(y\) (labels), i.e. \(y = f(x)\), based on the subset, or training data
\begin{equation}
    \mathcal{D}^{'}=\{(x_j, y_j), j \in Z := \{1,2,...m\}\}. 
\end{equation}
For classification \(y_j\) is a categorical finite set \(y_j \in \{1,2...C\}\) and for regression a real valued scalar \(y_j \in \mathbb R^{n}\). Each element \(x_j \in \mathbb R^{n}\) is a description of a sample and called feature vector.
In the unsupervised case, however, only inputs are given and 
\begin{equation}
    \mathcal{D}^{'}=\{x_j, j \in Z := \{1,2,...m\}\}. 
\end{equation}
Rather than a specific label in reinforcement learning the goal is to learn optimal actions to solve a certain problem by maximizing the reward linked to that action. However this type of machine learning is less commonly used in scientific enquiry and therefore not further described here.\\
\begin{figure*}[h]
  \dummyfig{Categories of ML} 
  \caption{Categories of ML}
  \label{fig1:ml_types}
\end{figure*}
Besides solving computational problems algorithms from machine learning offer additional value for scientific inquiry including the possibility for the automatic analysis of complex multidimensional data \cite{Brunton2019,Breiman2001}. In this approach, rather than assuming that data is generated by an underlying stochastic model as in classical statistical modelling the mechanisms are treated as unknown which may overcome inaccuracies in the analysis \cite{Breiman2001}. Furthermore, by extracting generalizable principles from the complex interaction of features it offers additional values to traditional hypothesis-driven approaches \cite{Vu1601,Bzdok2017}.\\

\subsubsection{Applications in neuroscience}
Both fields, research on \gls{ai} and neuroscience, are strongly interconnected as information processing in the brain serves as role model for the ultimate goal in \gls{ai} research, creating an artificial general intelligence system that matches or even surpass human intelligence \cite{Macpherson2021}. This led, for example, to the development of artificial neural networks, a class of machine learning algorithms that underlie modern advances in the field of \gls{ai} \cite{Cox2014}. Other examples are so called \glspl{cnn}, which are used in computer vision and inspired by the architecture of the visual ventral stream or \glspl{rnn} mimicking the functioning of working memory \cite{Macpherson2021, Fukushima1982, Yin2020}. On the other side, \glspl{cnn} and \glspl{rnn} are used to understand functional and organizational properties of the visual system \cite{Yamins2014} or working memory \cite{Kim2021} which highlights the bilateral relationship between machine learning and neuroscience and so its use in neuroscience is widespread. The goals incorporate not only solving practical problems in biomedical engineering or data processing, but also gaining insights and drawing conclusions by testing hypotheses and developing new theories.\\
Traditionally, machine learning has been the core building block for the development of intelligent systems that can automate tasks or enhance and assist humans in performing their tasks. Examples of automation in the field of neuroscience can be found, among others, in relation to the processing of neuroscientific data addressing low reproducibility and subjectivity. \citeauthor{Jas2017} \cite{Jas2017} use unsupervised machine learning to automate data prepossessing, i.e. rejecting and interpolating bad data segments, in the analysis of data from \gls{eeg} or \gls{meg}. In addition, machine learning is increasingly used for electrical source imaging to solve the inverse problem, i.e. finding neural sources that give rise to the recorded \gls{eeg} activity \cite{Cui2019,Hecker2021}. Other applications involve classification to automatically segment images from \gls{mri}, e.g. in grey or white matter, or the automatic detection and quantification of cell activation in calcium imaging \cite{Akkus2017}. In medical settings furthermore machine learning can be applied with the goal to support clinical decision making, i.e. assist in diagnosis, risk assessment by predicting health status or forecasting of treatment responses \cite{Woo2017}. Examples include classification to support the diagnosis of Alzheimer's disease based on EEG \cite{Gallego-Jutglà2015} or \gls{mri} \cite{Vemuri2008} data as well as the automated identification of lesions in radiographic brain images \cite{Zhou208} or the detection of epileptic seizures based on EEG data \cite{Vandecasteele2020}. Beyond that, machine learning is often used in developing devices with the goal to assist, augment or enhance humans capabilities such as \glspl{bci}. In \glspl{bci}, neural activity is decoded, using classification to generate control commands for various external devices such as computers or prosthetic limbs \cite{Saha2021, Anumanchipalli2019}. In this context unsupervised methods, i.e. dimensionality reduction, often are used to deal with the high dimensionality and variability of measured neural activity \cite{Brunton2019}.\\
While the examples described so far have focused on solving specific problems, machine learning algorithms provide mechanistic insights into the information structure of data and the generalizability of hypotheses \cite{Hastie2009}. Especially in areas where high-dimensional data is prevalent, such as in neuroscience, the use of supervised as well as unsupervised machine learning offers insight by extracting complex patterns purely data driven \cite{Bzdok2017}. Dimensionality reduction, for example, makes it possible to describe the structure of high-dimensional data with fewer properties \cite{Cunningham2014}. Two common methods in the analysis of neuroscientific data are \gls{pca} or \gls{ica} which are used to uncover meaningful patterns in the data. Especially \gls{ica} is increasingly applied to uncover brain networks based on \gls{fmri} data \cite{Varoquaux2010} or to uncover the statistical sources in \gls{eeg} which can be used to infer components of noise but as well on brain processes during behavior \cite{Strophal2018}.  In addition, with \gls{dmd}, \citeauthor{Brunton2016} \cite{Brunton2016} apply a method to \gls{ecog} that allows to map both the spatial and temporal structure of sleep spindle networks as well as task related brain networks involved in movements. Besides dimensionality reduction, clustering is used to identify subgroups at different levels ranging from molecules to participant groups giving rise to new testable hypothesis \cite{Vu1601}. By applying a nonlinear dimensionality reduction technique called \gls{umap} and clustering to data of extracellular waveforms recorded in the premotor cortex of macaques, \citeauthor{Lee2021} \cite{Lee2021} were able to identify subgroups of neurons with previously unknown diversity in terms of dynamics and laminar distribution. Furthermore, in another study analysing \gls{fmri} during different cognitive tasks, \citeauthor{Hawco2021} \cite{Hawco2021} assessed the variability structure of brain activation patterns and identified a spectrum of participants brain activation patterns that coincides with task performance. These results were only possible using advanced methods from machine learning. Besides unsupervised approaches, supervised approaches are being used to map brain function to external variables, such as group membership, behavior or stimuli, with the ultimate goal to identify predictive variables or features \cite{Glaser2019}. Under this objective classification of group membership, inferences can be made about the underlying mechanisms of the phenomenon under study. This is often of interest to inform clinical theory in the development of novel biomarkers, for example in autism \cite{Deshpande2013} or Alzheimer's disease \cite{Farina2020}, as well as in basic neuroscience. In this context, regression is used to predict the neural response to an external variable, such as a particular stimulus, to create a so-called encoding model, which can be used to test and compare brain computational theories \cite{Kriegskorte2019, Naselaris2011}. \citeauthor{Benjamin2018} \cite{Benjamin2018}, for example, show the superiority of using modern machine learning in predicting spike rates based on behavioral measurements. Contrary, decoding models are created with the goal to predict external variables from neural activity providing insights in the information content of neural measurements. This type of analysis is often referred to as \gls{mvpa} because its goal is to detect multivariate patterns, e.g., a set of voxels in fMRI or an electrical pattern at a given time in EEG, associated with an experimental condition based on goodness of classification or regression \cite{Holdgraf2017}. For example, neural dynamics in visual object perception \cite{Cauchoix2014} or working memory \cite{Bae2018} have been studied using decoding approaches applied to \gls{eeg} recordings. Decoding was also linked to another variable, such as group membership \cite{Csizmadia2021, Bae2020} or symptom scores \cite{Coutanche2011} , to reveal interesting interrelationships with neural representations of the condition under study.\\
In summary, the application of machine learning in neuroscience is diverse. In addition to a close theoretical integration of the two fields, machine learning offers solutions to engineering problems in supporting and augmenting human performance as well as in data processing. In basic sciences, it is used to extract patterns from highly complex data and gain insights into the predictive power of variables. This can contribute to the verification and formation of new hypotheses.




\subsubsection{Applications}
Start with short intro to aging and why there are plenty of interesting problems to solve with machine learning. Problems include
1. Engineering perspective\\
1.1. Concept of brain age as diagnostic marker\\  
1.2. Tools to assist and develop elderly: BCIs for different purposes (improvement of cognitive function  , i.e. neurofeedback, control of smart homes, rehabilitation of motor disabilities... See review. 
2. Scientific Perspective\\
Brain age 
MVPA of motor system Carp et al. 
CCA of motor system Zapparoli et al.



% SUBSUBSECTION {ABGRENZUNBG ZU KLASSISCH STATISTISCHEN VERFAHREN????}

% \subsection{Age related reorganization of the brain}
% \label{subsec:Aging}
% In general aging is an ongoing process that can be detected at multiple interacting biological systems operating on several spatial and temporal scales contributing to the complexity of the phenomenon \cite{Mooney2016}. The most prominent consequences of this are declines in cognitive and sensorimotor abilities challenging the daily life of older adults.
% Age related reorganization processes are detectable at the whole body. This is underpinned by multiple interacting biological systems operating on several spatial and temporal scales contributing to the complexity of the phenomenon \cite{Mooney2016}. At the behavioral level these processes are noticeable in changes in cognitive, motor and sensory functioning [QUELLE]. 
% On a structural level aging has been associated with a reduction in gray matter with an onset early in life 

% \subsubsection{Machine Learning usages in aging neuroscience}
% TEXT