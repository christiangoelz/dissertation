Machine learning emerged in the 1950s to enable computers to learn without being explicitly programmed \cite{Samual1959}. It is defined by computational methods combining fundamental concepts from computer science, statistics, probability, and optimization that automatically extract patterns and trends, i.e., \textit{learn} from data \cite{Hastie2009}. The notion of \textit{learning} therein describes the automated inference of general rules based on the observation of examples using algorithms to solve a specific task or problem \cite{Von_luxburg2011}. In its basic form, these tasks often involve making predictions based on learned relationships or extracting information based on automatically detected patterns and structures from data. Many real-world problems can be tackled by using machine learning. A rise in the methods started in the 1990s to 2000s with the availability of computing resources, data, and the development of algorithms, which have found their way into everyday life not only since the current advancements in generative \gls{ai} systems. Examples can be found in numerous areas, such as predicting stock prices, personalized advertising, or autonomous driving \cite{Rudin2014}.\\
In science, machine learning is increasingly used as a complementary method to classical statistical analyses because of the ability to make predictions and deal with the multidimensional structure and non-linearity in real-world datasets for drawing inference \cite{Bzdok2018}. Especially in areas where high-dimensional data is prevalent, such as in neuroscience, machine learning methods offer insight by extracting complex patterns in a data-driven way \cite{Brunton2019}. In terms of \gls{eeg}, machine learning can help identify subtle patterns and nonlinear relationships from the complex multidimensional structure of the data, allowing for more accurate and efficient analysis of brain recordings. Various methods are available for this purpose, which can be roughly characterized based on certain properties. 

\subsection{Forms of Machine Learning}
\label{theory:ml:forms}
The three main forms of machine learning are supervised, unsupervised, and reinforcement learning. These forms are defined by the type of feedback a machine learning algorithm has access to during learning \cite{Shalev2014}.\\
Supervised machine learning aims to learn a generalizable relationship between data and associated information, so-called labels or targets. The learned model can then be used to predict the label of new data that was not used during the learning process. If the labels are categorical, the prediction task is called classification; for continuous labels, the term is regression. Unsupervised machine learning aims to find hidden structures in data without considering associated labels. This could be grouping similar data points, i.e., clustering, or uncovering a meaningful low dimensional representation of high dimensional data, i.e., dimensionality reduction. This type of learning is also referred to as \textit{knowledge discovery} \cite{Murphy2012}. Reinforcement learning describes the task of learning optimal actions to solve a particular problem by maximizing the reward linked to that action. See \autoref{fig:ml_forms} for an overview of these three main forms.\\
\\

\begin{figure}[h]
\begin{center}
\begin{tikzpicture}[grow cyclic,
	level 2/.append style={level distance=2cm}]
\node[draw,ellipse,align=center,font=\bfseries\large]{Machine\\[-1ex]learning}
child[grow=145,level distance=4cm] { node[draw,ellipse,align=center] {Reinforcement\\[-1ex]learning}
}
child[grow=35, level distance=4cm] {  node[draw,ellipse,align=center] {Supervised\\[-1ex]learning}
	child[grow=-30, level distance=3.95cm] { node {Classification}}
	child[grow=-90]{ node {Regression}}
}
child[grow=-90, level distance=2.5cm] {node[draw,ellipse,align=center] {Unsupervised\\[-1ex]learning}
	child[grow=-160 ,level distance=3cm] { node[align=center] {Dimensionality reduction}}
	child[grow=-20,level distance=3cm] { node {Clustering}}
}
node at (-3.5,-0.2)[scale=0.8]{\input{figures/reinforcement.pdf_tex}}
node at (2.9,-4.65)[scale=0.2]{\input{figures/clustering.pdf_tex}}
node (node1) at (-4.3,-4.65)[scale=0.2]{\input{figures/dim_red3D.pdf_tex}}
node (node2) at (-1.75,-4.65)[scale=0.2]{\input{figures/dim_red.pdf_tex}}
node at (3.25,-0.75)[scale=0.2]{\input{figures/regression.pdf_tex}}
node at (6.5,-0.75)[scale=0.2]{\input{figures/classification.pdf_tex}}
;

\draw[->] (node1) -- (node2);

\end{tikzpicture}
\end{center}
\captionsetup{justification=justified}
\caption[The three main forms of machine learning.]{The three main forms of machine learning.}
\label{fig:ml_forms}
\end{figure}

\noindent In practice, however, a clear separation is often impossible. As such, dimensionality reduction can also be supervised, i.e., labels are provided to learn a new representation of the data \cite{Mcinnes2018}. Besides, in semi-supervised learning, the goal is the same as in supervised learning. However, the data set used to learn the relationship contains labeled and unlabeled examples. The hope is to build a stronger representation by providing more information in the form of data \cite{Burkov2019}. \\
In addition, traditional machine learning is often contrasted with deep learning methods involving artificial neural networks, which are composed of many layers of interconnected nodes often used in an end-to-end fashion in which the input data is used without any form of preprocessing. Usually, they require a vast amount of data and computational power. In the context of this thesis, the tasks considered involve the processing of \gls{eeg} from experiments with mid to small sample sizes to learn meaningful patterns and relationships in data. For this reason, a more detailed introduction to deep learning methods will not be given at this point. The following sections present state-of-the-art approaches for applications of traditional machine learning on \gls{eeg} data.

\begin{tcolorbox}[breakable, enhanced]
    \subsection*{Excursus: How does a machine learn?}
    "A computer program is said to learn from experience $E$ with respect to some task $T$ and some performance measure $P$, if its performance on $T$, as measured by $P$, improves with experience $E$" \cite{Mitchell1997}. In other words, learning in the context of machine learning typically involves solving a specific task by using algorithms that improve their performance by using example data. There are numerous algorithms designed to solve the problems outlined above. Some basic building blocks can be defined, which can be used to describe computational learning formally. In the following description, the view of statistical learning theory is considered, and notation is adapted from \citeauthor{Shalev2014} \cite{Shalev2014} and from \citeauthor{Von_luxburg2011} \cite{Von_luxburg2011}.\\
    \\
    Learning is always based on data, i.e., measurable information about some phenomenon, consisting of attributes of the phenomenon, so-called features, and an associated label in supervised learning. It is mathematically defined as an open bounded set $\mathcal{Z}\subset\mathbb{R}^n$ of dimension $n$. Typically there is only a set of examples or training data $S=\{z_i,...,z_m\}\subset{\mathcal{Z}}^m$ available, where $i = 1,\dots,m$, and each $z_i$ is sampled independently from $\mathcal{Z}$ according to an underlying probability distribution $\mathcal{D}$. Thus the only assumption is that the example data are independent and identically distributed. No assumption on $D$ is made.\\
    In supervised learning, $\mathcal{Z}$ comprises the space of input data $\mathcal{X}$ and the space of labels or output $\mathcal{Y}$. The example data $S$ consists of labeled input-output pairs $z_i=x_i,y_i\in(\mathcal{X}\times\mathcal{Y})^m$, where $x_i$ is an input data vector and $y_i$ is its corresponding output label. The pairs are sampled by some unknown joint probability distribution $\mathcal{D}$ on the space $\mathcal{X}\times\mathcal{Y}$.\\
    The space $\mathcal{Z}$ in unsupervised learning comprises the input data space $\mathcal{X}$ only and the example set $S$ consists of unlabelled examples $z_i=x_i\in\mathcal{X}^m$, sampled according to some unknown probability distribution $\mathcal{D}$ on the space $\mathcal{X}$.\\
    Learning ultimately can be thought of as approximating an underlying ground truth function $f$, also called model, that represents the relationship between input and output in supervised learning, i.e., 
    \begin{equation}
    f:\mathcal{X}\rightarrow\mathcal{Y},
    \end{equation}
    or the mapping to a space of hidden patterns or structure $\mathcal{W}\subset\mathbb{R}^p$, where $p$ can be equal or smaller than $n$, i.e.,
    \begin{equation}
    f:\mathcal{X}\rightarrow\mathcal{W}.
    \end{equation}
    A learning task can be conceptualized as searching through the space of all possible solution functions. As this is not feasible, a finite class of functions, so-called hypotheses, is typically selected a priory. Thus, learning can be thought of as selecting a hypothesis $h$ from a space of potential solutions $\mathcal{H}$ with $\mathcal{H}=\{h:\mathcal{X}\rightarrow\mathcal{Y}\}$ in supervised learning and $\mathcal{H}=\{h:\mathcal{X}\rightarrow\mathcal{W}\}$ in unsupervised learning. \\
    A learner or learning algorithm is the means of selecting the best element from $\mathcal{H}$.
    The cost of a false prediction or an inaccurate representation of the data is quantified using a loss function, $\ell:\mathcal{H}\times\mathcal{Z}\rightarrow\mathbb{R}_+$. In other words, it measures how well a specific hypothesis is doing.\\
    The expected risk is a measure of the average loss of a hypothesis, $h\in\mathcal{H}$ with respect to the probability distribution $\mathcal{D}$ over $\mathcal{Z}$ and can be defined as
    \begin{equation}
    L_{D}(h):=\mathbb{E}_{z\sim D}[\ell(h,z)]
    \end{equation}
    A learner should select a hypothesis with the lowest possible expected risk. However, the underlying probability distribution is unknown. Using $S$, the expected risk can be estimated using the empirical risk over the training data. This is defined by:
    \begin{equation}
    L_{S}(h):=\frac{1}{m}\sum_{i=1}^m\ell(h,z_i).
    \end{equation}
    Following this, learning can be formalized as solving an optimization problem of the form: 
    \begin{equation}
    \hat{h}=\arg\min_{h\in\mathcal{H}}L_{S}(h),
    \end{equation}
    which can be solved computationally. In parameterized models, this often involves the automated selection of those parameters $\theta\in\Theta$ of a chosen class of models that minimize $L_{S}(h_\theta)$. This optimization problem can then be solved by methods such as gradient descent or, e.g., analytically, using least squares estimation. The solution $\hat{h}$ is the learned model that can be used to solve the task at hand, e.g., predicting the label of new input data or uncovering patterns or structures in data. This is known as \gls{erm}.\\
    Upon \gls{erm}, more complex learning paradigms can be used to address common problems such as overfitting, in which the learned hypothesis too closely relies on the training data and therefore has low generalization performance, e.g., regularized risk minimization, which introduces regularization to \gls{erm} or structural risk minimization that penalizes complex models and encourages simplicity.\\
    \\
    Although most machine learning can be conceptualized within the framework of \gls{erm}, there are models that, instead of minimizing risk, assume that the underlying distribution over the data has a specific parametric form, and the goal is to estimate these parameters by using \gls{mle} which seeks to find the model parameters that maximize the likelihood of the observed data under the assumed parametric distribution, i.e., \\
    \begin{equation}
    \hat{\theta}_{\text{MLE}} = \arg\max_{\theta\in\Theta}\prod_{i=1}^{m}p_{\theta}(z_i),
    \end{equation}
    where $p_{\theta}(z)$ is the joint probability function of the assumed parametric distribution and $\hat{\theta}_{\text{MLE}}$ is the estimated value of the parameter vector $\theta$.
\end{tcolorbox}

\subsection{State-of-the-Art Approaches to Electroencephalographic Data}
\label{theory:ml:applications_eeg}
Various established supervised and unsupervised algorithms have been utilized in the analysis of \gls{eeg} data, and the selection is usually based on the goal of the analysis. Unsupervised learning aims to highlight specific information in the data, so the selection is made based on the information one aims to highlight \cite{Shalev2014}. This is to highlight group structure in \gls{eeg} data when using clustering or to highlight \gls{eeg} inherent characteristics in dimensionality reduction. In contrast, selecting a suitable supervised learning algorithm is more guided by its performance, i.e., its ability to derive generalizable rules that allow predictions from the available data. Typically, different classification algorithms and their parameters are selected, trained on one portion of the data, the so-called training data, and then tested for their performance on data not used for training, the so-called testing data \cite{Daumé2017}. The training data can further be divided into a training and validation portion to compare different model types or user-defined learning algorithm settings, so-called hyperparameters. Finally, the best model configuration is tested for its predictive performance on the test data and reported. However, this three-time division may drastically reduce the data size usable for training and may result in flawed generalization evaluation due to the randomness of the split \cite{Varoquaux2017}. Therefore several procedures can be applied. In simple k-fold cross-validation, for example, the training data is divided k-times. Thus each time, a different subset of the data is used for validation while the rest is used for training. Usually, this is repeated for a range of models and subsequent hyperparameters, and the model and hyperparameter performing best on average are selected for final testing. Building on this, 
nested cross-validation can be used to select the best model and test the generalization performance by adding a second cross-validation loop for the final model evaluation. In this way, an unbiased estimation of the generalization performance of a model can be obtained (see Figure \ref{fig:CV} for a visual representation of the procedure).

\begin{figure*}[ht]
\centering
  \input{figures/nested_cv.pdf_tex}
  \captionsetup{justification=justified}
  \caption[Exemplary nested cross-validation procedure.]{Exemplary nested cross-validation procedure. K-fold cross-validation is used in an outer loop for testing the best configuration tuned in an inner cross-validation loop. CV: cross-validation, Val: Validation}
  \label{fig:CV}
\end{figure*}

\noindent Recent work highlights deep neural networks that can be used for unsupervised and supervised machine learning applications to \gls{eeg} \cite{Roy2019}. However, their advantage comes into play with large data resources, which are often expensive to acquire in the case of \gls{eeg} \cite{Banville2021}. Traditional learning approaches can be more efficient with good performance and promise better interpretability, especially for comparatively smaller datasets and limited computational resources \cite{Gemein2020}. Due to the low signal-to-noise ratio and high complexity of \gls{eeg} data, the inputs in these approaches are often represented by well-known \gls{eeg} characteristics or features that are believed to be related to the problem being learned. Typical features include time, frequency, time-frequency, connectivity, and theoretical information parameters extracted for each sensor (see \citeauthor{Gemein2020} \cite{Gemein2020} for common choices). However, this approach may lead to less flexible and generalizable models with low spatial resolution and vulnerability to low signal-to-noise ratios \cite{Saeidi2021}.\\
Some approaches to address these problems compute the anatomical sources of the \gls{eeg} signals in the brain using biophysical models as a preprocessing step prior to feature extraction \cite{Khan2018, Westner2018}. However, they require a head model based on \gls{mri} often unavailable individually or merely estimated based on existing templates. Other approaches use supervised and unsupervised decomposition techniques belonging to the field of dimensionality reduction as a preprocessing step for further prediction tasks or provide information themselves in the sense of knowledge discovery. These methods aim at \textit{unmixing} the highly correlated sensor time series by assumptions about the underlying signal components. For example, \gls{ica} assumes statistical independence. In contrast, \gls{pca} assumes that the extracted components are maximally uncorrelated to each other, capturing the largest amount of variance in the data \cite{CohenX2017}. \Gls{dmd} is a method that explicitly considers the temporal structure of the signals, which requires that the extracted signal patterns (modes) are dynamically coherent, extracting spatiotemporal coherent structures and thus accounting for the network nature of the brain \cite{Brunton2016}. Additionally, supervised methods such as \gls{csp} \cite{Blankertz2008} or xDAWN \cite{Rivet2009} extract signal components that correlate with the labels to be predicted.\\
While the supervised and unsupervised dimensionality reduction methods mentioned so far offer ways of examining the complex \gls{eeg} signals in terms of components and patterns to generate knowledge, non-linear methods such as \gls{tsne} and \gls{umap} take into account the non-linear relationships between the data points and provide a lower-dimensional representation of the data that is often easier to interpret and visualize \cite{Mcinnes2018}. These methods can be beneficial for exploring the relationships between different \gls{eeg} features or identifying subgroups within a dataset.\\
It is important to note that these methods can be applied not only to the \gls{eeg} signals themselves but also to previously extracted \gls{eeg} parameters or in combination in terms of knowledge discovery. Thus, supervised and unsupervised dimensionality reduction provides data-driven insights into the complex underlying information but also serves as preprocessing for further tasks such as prediction.

\subsection{Applications in the Context of Aging Research}
\label{theory:ml:applications_aging}
Traditionally, the previously presented machine learning approaches have been the core building block for developing intelligent systems that can automate tasks or enhance and assist humans in performing their tasks. Such systems are critical in terms of assistive technology, for example, to support older adults with disabilities to live their daily lives, but are also relevant in the medical field. In the latter, the hope is to develop intelligent medical systems to inform clinical theory and support clinical decision-making, i.e., assist in diagnosis and risk management by predicting health status or forecasting treatment responses \cite{Woo2017}. In this context, supervised learning is often used to identify markers from \gls{eeg} by identifying signal features that are predictive of a particular disease or health condition, which is highly important in promoting a healthy aging trajectory \cite{Babiloni2021,Mei2021}. An application, known as brain age estimation, is to estimate biological age based on a regression model trained on neural data, e.g., \gls{eeg} data, recorded in extensive population studies \cite{Engemann2022}. The model can then be used to predict the age of an individual. If the brain appears older than it would chronologically, i.e., if the gap between predicted and actual age is large, this may be an early indication of an unfavorable state of health \cite{Gonneaud2021}.\\
Another highly relevant application in the context of aging is the development of devices to assist, augment or enhance humans' capabilities, such as \glspl{bci}. In \glspl{bci}, neural activity is decoded, using classification to generate control commands for various external devices such as computers or prosthetic limbs \cite{Saha2021, Anumanchipalli2019}. Decoding refers to learning a classification or regression model that predicts behavioral outcomes or cognitive states based on neural data. \\
Beyond the application in \glspl{bci}, decoding techniques are widely used in neuroscientific research to gain insights into the neural mechanisms underlying perception, cognition, and behavior. This type of analysis is often referred to as \gls{mvpa} because its goal is to detect multivariate patterns, e.g., a set of voxels in \gls{fmri} or an electrical pattern at a given time point in \gls{eeg}, associated with an experimental condition \cite{Holdgraf2017}. While the use has a long history in the field of \gls{fmri} analysis, it has only become more widespread in the field of \gls{eeg} in recent years. Therefore, decoding approaches to understanding age-related reorganization are mostly limited to \gls{fmri} studies. A common approach is to measure dedifferentiation at the individual level, i.e., the loss of neural specificity. Since dedifferentiation, by definition, results in more similar brain activation patterns for different tasks or stimuli, a poorer performance of classifiers trained to discriminate between them based on neural recordings is indicative of a less distinctive neural representation \cite{Koen2019, Park2010}. However, the literature on the application of this approach to \gls{eeg} data is minimal and restricted to single studies \cite{Chen2019}.\\
Classifying group membership or group-level regression can provide additional information about interesting relationships and their generalizability at the group level. Particularly for \gls{eeg} markers representing functional network characteristics can reveal insightful findings about the relationship to age-related changes \cite{Petti2016}.\\
In addition to typical statistically motivated analysis methods that calculate bivariate connectivity between sensors based on the phase difference or coherence of the \gls{eeg} signals, dimensionality reduction techniques, such as the aforementioned \gls{dmd}, provide a data-driven way to capture dynamic brain network characteristics. This approach has already been used to map age- or expertise-related changes related to brain networks \cite{Vieluf2018}. Further, unsupervised methods, such as nonlinear dimensionality reduction techniques, were frequently used to describe the structure of data sets with respect to age-related changes \cite{Banville2021,Kottlarz2020}.\\
\\
In summary, machine learning is very diverse and ranges from engineering applications to scientific knowledge discovery. Especially in the latter case, it offers the advantage of automated extraction of patterns from highly complex data that can contribute to studying age-related changes. While decoding approaches are particularly interesting for measuring age-related changes in the organization of neural systems, such as the level of differentiation, group analysis could provide new insights into datasets. Especially classification methods that predict a particular experimental condition or a group membership are particularly suitable. The combination with unsupervised learning algorithms, such as dimensionality reduction methods, could be particularly beneficial and used to visualize high-dimensional data.


