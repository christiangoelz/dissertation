\section{Datasets}
The datasets were selected from experiments in published projects in which different study paradigms were used to investigate age-related differences between age groups and groups with different lifestyle backgrounds. The following is a brief description of the datasets. \autoref{tab:overview-ds} gives an overview of which datasets were used in the respective research articles \uproman{1} to \uproman{4}.

\subsection{Dataset \uproman{1}}
\label{methods:datasets:I}
Dataset \uproman{1} was collected as part of the Bremen Hand Study@Jacobs, which investigated the influence of age and expertise on hand dexterity over the working life \cite{Voelcker-Rehage2013}. This dataset was analyzed in research article \uproman{1} \cite{Goelz2021a} and \uproman{4} \cite{Gaidai2022}.

\subsubsection{Participants}
\label{methods:datasets:I:participants}
The dataset contains recordings from 59 participants, Based on their age and occupation, participants were labeled as young novice, middle-aged novice, old novice, middle-aged expert, or old expert. Novices were defined as occupational profiles whose daily routine does not require fine motor control of the hands, such as service personnel, insurance agents, office workers, and students. Experts, on the other hand, referred to persons with more than 10 years of professional experience in a job with pronounced fine motor requirements for hand control such as opticians, goldsmiths, dentists, dental technicians, or hearing aid technicians \cite{Ericsson1991}. In research article \uproman{1} only the young novices (N=13, age: 18 to 25 years) and old novices (N=13, age: 55 to 65 years) were considered. In research article \uproman{4} all middle-aged and old experts (N=22, age: 34 to 65 years) as well as all middle-aged and old novices (N=21, age: 35 to  64)

\subsubsection{Experimental Procedures}
\label{methods:datasets:I:experiment}
The experiment conducted was a force-tracking experiment conducted blockwise (see \autoref{fig:DSI_exp1} and research article \uproman{1} and \uproman{2} for experimental details). The task was to apply the correct force to a force transducer using the right or left hand to track a target force level as precisely as possible. A total of 160 trials were conducted. The first 40 trials involved a steady force level and the following 40 trials a sine force level. The sequence was then repeated with the left hand.\\
Grip force and \gls{eeg} were recorded. Before the experiments resting \glspl{eeg} with eyes open and eyes closed were recorded for 30 s each while participants sat comfortably on a chair.

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_1.pdf_tex}
\caption[Schematic presentation of the force-tracking task conducted in dataset \uproman{1}.]{Schematic presentation of the force-tracking task conducted in dataset \uproman{1}. The task was to apply the correct force to a force transducer using the right or left hand to track a target force level (green line) as precisely as possible. Participants received feedback, i.e., they saw their applied force (yellow line).}
\label{fig:DSI_exp1}
\end{center}
\end{figure}

\subsection{Dataset \uproman{2}}
\label{methods:datasets:II}
Dataset \uproman{2} contains recordings from three experimental studies, each focusing on a different age group and referred to below as Study 1, Study 2, and Study 3.\\
Study 1 is the Bremen-Hand-Study@Jacobs presented above. Study 2 is the Re-LOAD project, which investigated the relationship between motor learning and cognitive function in older adults \cite{HUBNER2018104, Hübner2018}. Study 3 is the CEBRIS project, in which the influence of physical training on the cognitive functions of children was investigated \cite{Koutsandreou2016}. The dataset is described detailed in \cite{Reuter2019} and was analyzed in research article \uproman{2}

\subsubsection{Participants}
\label{methods:datasets:II:participants}
The full dataset contains recordings from a total of 222 participants including 92 participants recorded in Study 1, 81 participants recorded in Study 2, and 49 participants recorded in Study 3.\footnote{In the sample used here 13 participants were excluded due to bad data quality.}. Participants are separated into the following age categories \cite{Reuter2019}: children (N=46, age: 8 to 10 years), young adults (N=39, age: 20 to 29 years), early middle-aged adults (N=21, age: 36 to 48 years), late middle-aged adults (N=25, age: 55 to 64), old adults $<$75 (N=40, age: 66 to 75 years), very old adults $>$75 (N=38, age: 76 to 83 years).

\subsubsection{Experimental Procedures}
\label{methods:datasets:II:experiment}
All participants performed a modified version of the Flanker task previously reported in \cite{Reuter2017, Winneke2012, Winneke2019}, and summarized in \cite{Reuter2019} (see \autoref{fig:DSII_exp2} and research article uproman{2}). The task was to press the correct button corresponding to a central target stimulus surrounded by distracting flanker stimuli. In Study 1 and Study 3, participants performed 300 trials (approx. 100 trials per stimulus), whereas in Study 2, they performed 150 trials (approx. 50 trials per stimulus) in randomized order. Participants did a minimum of 20 practice trials and were asked to respond as fast and precisely as possible. Other than this the same experimental procedures were applied in all studies including the \gls{eeg} measurements system. 

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_2.pdf_tex}
\caption[Schematic presentation of the flanker task conducted in dataset \uproman{2}.]{Schematic presentation of the flanker task conducted in dataset \uproman{2}.}
\label{fig:DSII_exp2}
\end{center}
\end{figure}

\subsection{Dataset \uproman{3}}
\label{methods:datasets:III}
Dataset \uproman{3} was collected during an intervention study at Paderborn University. The dataset is described in detail in research article \uproman{3} \cite{Goelz2021b}. 

\subsubsection{Participants}
\label{methods:datasets:III:participants}
The dataset contains recordings from 41 elderly participants. Based on their performance on a 6 min walking test participants’ cardiorespiratory fitness was assessed in preceding appointments and two groups were formed, a less fit (N=16, age: 63 to 77 years) and a fit group (N=15, age: 60 to 66 years) (see research article \uproman{3} \cite{Goelz2021b} for details).

\subsubsection{Experimental Procedures}
\label{methods:datasets:II:experiment}
Participants performed sensory, motor, and cognitive tasks each lasting 90 s during which \gls{eeg} was recorded (see \autoref{fig:DSII_exp3}. Prior to the tasks, \gls{eeg} was recorded for four minutes in a rest condition in a supine position with eyes closed. 
\paragraph{Motor task} 
The motor task corresponded to a force tracking experiment as described in \autoref{methods:datasets:I:experiment}. Here, the target was a line that moved from the right to the left on the screen for 90 s and changed level every 3 s in randomized order between heights that represented 10\%, 20\% and 30\% of participants' individual \gls{mvc}.
\paragraph{Cognitive task}
The cognitive task was an auditory n-back task. In essence, participants were asked to listen to a sequence of letters presented via two speakers behind them and press the foot switch with the right foot if a letter appeared again two letters later (2-back).
\paragraph{Sensory task}
Participants' index fingertip of the left hand were stimulated with the pins of a braille device presenting two pin configurations in random order. 

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_3.pdf_tex}
\caption[Schematic presentation of the motor, sensory and cognitive tasks conducted in dataset \uproman{3}.]{Schematic presentation of the motor, sensory and cognitive tasks conducted in dataset \uproman{3}.}
\label{fig:DSII_exp3}
\end{center}
\end{figure}

\begin{table}[h]
\captionsetup{justification=raggedright,singlelinecheck=false}
\caption{Overview of datasets and participants in each research article.}
\label{tab:overview-ds}
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{}  & \textbf{Dataset} & \textbf{Paradigm} & \multicolumn{2}{l}{\textbf{Participants}} \\ \midrule
Research Article \uproman{1} & Dataset \uproman{1} & Force Control  & Young adults & N=13, age: 55 to 65 years \\
 & & & Old Adults & N=13, age: 18 to 25 years \\ \midrule
Research Article \uproman{2}  & Dataset \uproman{2} & Flanker  & Children & N=46, age: 8 to 10 years  \\
 & & & Young adults & N=39, age: 20 to 29 years \\
 & & & Early middle-aged adults & N=21, age: 36 to 48 years \\
 & & & Late middle-aged adults  & N=25, age: 55 to 64  \\
 & & & Old adults \textless{}75 & N=40, age: 66 to 75 years \\
 & & & Old adults \textgreater{}75 & N=38, age: 76 to 83 years \\ \midrule
Research Article \uproman{3}  & Dataset \uproman{3} & Nback & Low fit & N=16, age: 63 to 77 years \\
 & & Tactile Oddball & Fit  & N=15, age: 60 to 66 years \\
 & & Force Control  &  & \\\midrule
Research Article \uproman{4} & Dataset \uproman{1} & Force Control  & Experts & N=22, age: 34 to 65 years \\
 & & & Novices & N=21, age: 35 to  64 \\ \bottomrule
\end{tabular}
\end{table}

\newpage
\section{Machine learning procedures} 
We aimed at uncovering brain reorganization by using methods from the field of machine learning. Following state of the art approaches (see \autoref{theory:ml:applications_aging}) we used a combination of dimensionality reduction methods and classification. Dimensionality reduction was used to extract a suitable representation of the EEG data for the following classification, i.e. for feature extraction, and also to detect and visualize patterns in the data sets. Classification procedures were used both at the individual level as well as at the group level. The former means that one model per subject was trained, which represents the cortical representation of an experimental condition, e.g., a task, and finally allows conclusions, e.g., about the dedifferentiation of cortical processes at the individual level. The latter means that a model was trained for the whole group to detect general overlapping patterns in the group structure. The selection of a suitable method was based on the dataset, i.e. data structure and experimental conditions, and the aim of the analysis. This approach is visualized in \autoref{fig:ML_approach} and Table \autoref{tab:ml_methods}  summarizes the used methods for each research article. In the following, the methods will be briefly described. The exact pipelines are described in the appended research articles \uproman{1} to \uproman{4}.

\begin{figure}[h]
\begin{center}
\input{figures/ml_approach.pdf_tex}
\caption[Machine learning approach used in this thesis]{Machine learning approach used in this thesis. Dimensionality reduction was used to produce a suitable representation of the \gls{eeg} data (1). Optionally a second level dimensionality reduction was applied to extract patterns and for visualization (1b). Finally Classification was used to classify either the task at individual level or the group membership (2) using either the results of 1a or 1b.}
\label{fig:ML_approach}
\end{center}
\end{figure}

\begin{table}[ht]
  \begin{threeparttable}
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \caption{Dimensionality reduction and classification methods utilized in each research article}
    \begin{tabular}{@{}p{3cm}p{2cm}p{2.5cm}p{2cm}p{2cm}@{}}
      \toprule
       & \multicolumn{2}{l}{\textbf{Dimensionality Reduction}} & \multicolumn{2}{l}{\textbf{Classification}} \\ \cmidrule(l){2-5} 
      & 1st level & 2nd level & Task & Group \\ \midrule
      Research Article \uproman{1}  & DMD & CSP & LDA & SVM \\
      Research Article \uproman{2}  & xDAWN & -   & SVM  & SVM \\
      Research Article \uproman{3}  & DMD & CSP, UMAP & LDA  & SVM  \\
      Research Article \uproman{4}  & DMD & PCA       & -    & -    \\
      \bottomrule
    \end{tabular}
    \begin{tablenotes}
      \small
      \item DMD: dynamic mode decomposition, CSP: common spatial patterns, LDA: linear discriminant analysis, SVM: support vector machine, PCA: principal component analysis
    \end{tablenotes}
  \end{threeparttable}
\end{table}


\newpage
\subsection{Dimensionality reduction}

\subsubsection{Dynamic mode decomposition}
To extract a relevant representation of the continuous \gls{eeg} activity, we chose \gls{dmd} because it is able to decompose the signals into spatial activation patterns that are dynamically coherent, reflecting the network nature of the underlying brain activity \cite{Brunton2016}. \Gls{dmd} was developed in the field of fluid mechanics and was applied to various fields to model time-varying dynamical systems including neuroscience proving to extract physiological valid signal patterns \cite{Brunton2016, Kunert-Graf2019, Schmid2010, Schmid2008}. The activation patterns (modes) extracted from \gls{dmd} analysis can reveal key features such as the spatial distribution of coherent dynamics in relation to oscillation frequencies and mechanisms of growth or decay. This provides a deeper understanding of the functional reorganization of the brain and can serve as a starting point for further analysis \cite{Brunton2016}.\\
For the computation of \gls{dmd}, the \textit{exact \gls{dmd}} algorithm introduced by \citeauthor{Tu2014} \cite{Tu2014} and described in \cite{Brunton2016} as applied to electrophysiological data. The analysis was based on the preprocessed and windowed \gls{eeg} data and \gls{dmd} modes associated with the frequency ranges $\theta$ (4 to $<$ 7 Hz), $\alpha$ (7 to $<$ 12 Hz), $\beta_1$ (12 to $<$ 16 Hz), and $\beta_1$ (16 to $<$ 30 Hz) were considered. We calculated the \gls{dmd} mode magnitude (absolute value) to obtain the influence of each electrode in a \gls{dmd} mode representing spatially coherent activation \cite{Brunton2016}.

\subsubsection{Principal component analysis}
\Gls{pca} aims at extracting the statistically most descriptive components from highly dimensional data \cite{Brunton_kutz_2019}. For this we used the \gls{svd} algorithm and reduced the dimension of all time windows to their main features. We calculated a \gls{svd} over all frequency specific modes over all time windows per participant and extracted the singular vectors and singular values. The singular vectors represent the principal components and capture the most significant data patterns while the singular values capture the proportion of variance accounted for by this pattern. Higher singular values indicate that the associated dominant mode captures more variation among all \gls{dmd} modes during task completion and can be considered representative of the stability or prominence of this pattern.

\subsubsection{Uniform manifold matrix approximation and projection}
While \gls{pca} was used to explain patterns of variation within a participant, we relied on \gls{umap} to capture the structure both on a local level, i.e. within a participant, as well on a global level, i.e. between participants. \Gls{umap} constructs a low-dimensional representation by modeling the data as a topological manifold, considering both the distances between data points and the local density, and is particularly effective in visualizing and exploring complex data patterns and meaningful relationships in the data \cite{mcinnes2018umap}. For this we first calculated the arithmetic mean over the \gls{dmd} modes of all windows per frequency band, trial, and participant and then applied \gls{umap} to obtain a lower-dimensional representation that captures underlying patterns and meaningful relationships in the data, facilitating visualization and exploration of \gls{dmd} patterns.

\subsubsection{Common spatial patterns}
To extract the information from the \gls{dmd} modes that would allow the best possible differentiation between the tasks we leveraged supervised dimensionality reduction (see \autoref{theory:ml:applications_eeg}). This approach is based on \gls{fbcsp} a widely used algorithm for the classification of continuous tasks that extracts a weighting for each \gls{eeg} channel that maximizes the class discriminative energy for selected frequency bands \cite{ang2012filter}. By multiplying these weights with the channel values, meaningful features are generated. The weightings were calculated based on \gls{dmd} magnitudes in each frequency band (see research article \uproman{1} \cite{Goelz2021a} for details on the implementation).

\subsubsection{xDAWN}
To process the event-related \gls{eeg} data we relied on the xDAWN algorithm \cite{rivet2009xdawn}. Similar to \gls{csp} by applying the xDAWN algorithm it is possible to obtain a set of weights that emphasize the relevant \gls{eeg} activity while suppressing noise and artifacts, leading to improved signal quality for further analysis or classification tasks. In this way, it is possible to induce activation patterns, i.e. neural responses to external stimuli at the level of individual trials. In contrast to the previous methods, we did not use DMD first but applied xDAWN to the preprocessed trials as originally described to ensure comparability to previous \gls{erp} analyses \cite{Reuter2019}.\\

\subsection{Classification}
Classification was performed on a trial-by-trial basis, i.e. models were learned that can predict for each participant to which task a given trial belongs or cross-participant to which group the performing subject belongs. Typically, different classification algorithms and their parameters are selected, trained on one portion of the data, the so-called training data, and then tested for their performance on data not used for training, the so-called testing data \cite{Daumé2017}. The training data can further be divided into a training and validation portion in order to compare different model types or user defined settings of learning algorithms, so-called hyperparameters. Finally, the best model configuration is tested for its predictive performance on the test data and reported. However, this three time division may drastically reduce the data size usable for training and my result in flawed generalization evaluation due to the randomness of the split \cite{VAROQUAUX2017166}. Therefore several procedures can be applied. In simple k-fold cross-validation, for example, the training data is divided k-times. Thus each time a different subset of the data is used for validation while the rest is used for training. Usually, this is repeated for a range of models and subsequent hyperparameters and the model and hyperparameter performing best on average are selected for final testing. We used a more advanced method denoted nested cross-validation, which adds a second cross-validation loop for the final model evaluation (see Figure \ref{fig:CV} for a visual representation of the procedures).

% \begin{figure*}[h]
%   \input{figures/nested_cv.pdf_tex} 
%   \caption[Nested cross-validation procedure]{Nested cross-validation procedure. CV: cross-validation, Val: Validation}
%   \label{fig:CV}
% \end{figure*}

For all datasets, 10 splits were used in the inner and outer cross-validation loops, keeping 80\% of the dataset for training and 20\% for testing. In the inner loop, hyperparameters were tuned according to a grid search procedure in which a given parameter space is provided to comprehensively select the best fitting parameters \cite{VAROQUAUX2017166}. Consequently, one model was tested for each of the 10 outer splits. The final metrics are the average over the outer splits and represent the performance of the classification algorithm. For classifiers, these can be derived using a so-called confusion matrix (\autoref{tab:confusion-matrix}), which summarizes all correct and false predicted instances of the test set \cite{Fawcett2006}.  

\begin{table}[ht]
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \caption{Confusion Matrix}
    \label{tab:confusion-matrix}
    \renewcommand{\arraystretch}{1.25}
    \centering
        \begin{tabular}{cc|c|c|}
            \cline{3-4}
            & & \multicolumn{2}{c|}{Predicted Class} \\ \cline{3-4} 
            & & Positive & Negative \\ \hline
            \multicolumn{1}{|c|}{\multirow{2}{*}{Actual Class}} & Positive & True Positive (TP) & False Negative (FN) \\ \cline{2-4} 
            \multicolumn{1}{|c|}{} & Negative & False Positive (FP) & True Negative (TN) \\ \hline
        \end{tabular}
\end{table}

\noindent If an actual value is positive and is classified as positive, it is a \gls{tp} result. If the positive instance is classified as negative, it is a \gls{fn} result. If an instance is actually negative and classified as negative, it is called \gls{tn}. Consequently, if an instance is negative and classified as positive, it is a \gls{fp} \cite{Fawcett2006}. This forms the basis for various metrics reported in the research articles. \autoref{tab:metrics-summary} summarizes the metrics and their meaning.

\begin{table}[h]
  \begin{threeparttable}
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \caption{Summary of Metrics}
    \label{tab:metrics-summary}
    \renewcommand{\arraystretch}{1.25}
    \begin{tabular}{@{}p{3.5cm}p{4cm}p{6.5cm}@{}}
        \toprule
        \textbf{Metric} & \multicolumn{1}{c}{\textbf{Formula}} & \multicolumn{1}{c}{\textbf{Description}}\\ 
        \midrule
            Accuracy & \centering$\displaystyle\frac{TP + TN}{TP + TN + FP + FN}$ & Measures the overall correctness of the model's predictions.\\
            Precision & \centering$\displaystyle\frac{TP}{TP + FP}$ & Measures the proportion of true positive predictions among all positive predictions.\\
            Recall (Sensitivity) & \centering$\displaystyle\frac{TP}{TP + FN}$ & Measures the proportion of true positive predictions among all actual positive samples.\\
            Specificity & \centering$\displaystyle\frac{TN}{TN + FP}$  & Measures the proportion of true negative predictions among all actual negative samples.\\
            F1 Score & \centering$\displaystyle\frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$  &  Harmonic mean of precision and recall, providing a balanced measure between the two.\\
            AUC & \centering- & Area under the receiver operating characteristic curve which measures the performance of a binary classification model across various threshold settings. \\
        \bottomrule
    \end{tabular}
    \begin{tablenotes}
    \small
    \item TP: true positive, TN: true negative, FP: false positive, FN: false negative, AUC: area under the receiver operating characteristic curve
    \end{tablenotes}
\end{threeparttable}
\end{table}

In this study, we experimented with multiple algorithms based on recent literature to find the most suitable models for the respective tasks. In doing so, we finally used \gls{svm} and \gls{lda}, which both have a wide history of application to neuroscience data and are well suited to our specific problems.  \Glspl{svm} is one of the most commonly used algorithms for neuroscience data \cite{VAROQUAUX2017166}. The algorithm generates optimal decision boundaries, called hyperplanes, and can thus handle both linearly separable and non-linearly separable data by using kernel functions to map the input space into a higher-dimensional feature space. \Gls{lda} is specifically used in the context of \Gls{bci} and has proven to be successful in task decoding \cite{Blankertz2008}. This algorithm aims to find a linear combination of features that maximizes the separation between different classes, making it particularly effective in situations where the classes are well-separated \cite{shoorangiz2021eeg}. 


% Given \gls{eeg} data containing measurements $x_k$ sampled every $\Delta t$ by $n$ electrodes over $m$ time points, two matrices $X$ and $X'$ can be constructed, where $X'$ are the data points of $X$ shifted by one $\Delta t$, i.e,
% \begin{equation}
% X = \begin{bmatrix}
%     | & | &  & |\\
%     x_1 & x_2 & \dots & x_{n-1}\\
%     | & | &  & |
% \end{bmatrix}
% \label{eqn:X}
% \end{equation}
% and
% \begin{equation}
% X' = \begin{bmatrix}
%     | & | &  & |\\
%     x_2 & x_3 & \dots & x_n\\
%     | & | &  & |
% \end{bmatrix},
% \label{eqn:X'}
% \end{equation}
% The relationship between the matrices $X$ and $X'$ can be represented by a linear operator $A$ which characterizes the underlying dynamics in terms of the relationship between $x_k$ and $x_{k+1}$, such that
% \begin{equation}
% \label{eq:dmd_model}
% X' = AX.
% \end{equation}
% The eigendecomposition of $A$ is referred to as \gls{dmd} and yields the spatial patterns, i.e. \gls{dmd} modes, and associated eigenvalues. In this thesis, the \textit{exact \gls{dmd}} algorithm as reported by \cite{Brunton2016} was applied to compute these quantities. Based on this an approximation $\hat{X}$ of the observed measurements $X$ by defining the dynamical model
% \begin{equation}
%     \hat{X}=\Phi exp(\Omega t) z
% \end{equation}
% Every column of $\Phi$ is a DMD mode $\phi_i$ and the matrix $\Omega$, expressed by $\Omega=\log(\lambda)/\Delta t$, reveals the dynamics of the system, where the diagonal matrix $\Lambda$ contains the DMD eigenvalues, i.e., eigenvalues of $A$, on its diagonal. The variable $t$ represents time and $z$ is a constant vector that can be determined from the first time point in each channel, i.e., $x_i = \Phi z$. Each value $\omega_i$ in $\Omega$ corresponds to $\phi_i$ and describes its dynamic behavior in terms of growth, decay, and oscillation. Thus, the oscillation frequency in cycles per second (Hz) of each mode can be determined by $f_i = imag(\omega_i)/2\pi$.

% \subsubsection{Machine learning pipelines}
% Training testing 
% Evaluation

% % To approximate the performance of a classification model a dataset is typically divided into a training and testing set. The training set is used for learning a model whereas the testing set is used to estimate the generalization performance to new unseen data, i.e. data which was not used during the process of training. The training data can further be divided into a training and validation portion in order to compare different model types or user defined settings of a learning algorithms, so called hyperparameters. However, this three time division may drastically reduce the data size usable for training and my result in flawed generalization evaluation due to the randomness of the split. Therefore several procedures can be applied. In a simple k-fold cross-validation, for example, the training data is divided k-times. Thus each time a different subset of the data is used for validation while the rest is used for training. Usually this is repeated for a range of models and subsequent hyperparamters and the model and hyperparameter performing best on average are selected for final testing. A more advanced method denoted nested cross-validation adds a second k-fold cross-validation loop for the final model evaluation (see Figure \ref{fig1:CV} for a visual representation of the procedures).    

% % \begin{figure*}[h]
% %   \dummyfig{Cross-validation procedures} 
% %   \caption{Cross-validation procedures}
% %   \label{fig1:CV}
% % \end{figure*}
