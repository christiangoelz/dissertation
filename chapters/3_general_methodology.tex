\section{Datasets}
The datasets were selected from experiments in already published projects in which different study paradigms were used to investigate age-related differences between age groups and groups with different lifestyle backgrounds. The following is a brief description of the datasets. All included participants gave their written informed consent. For children, guardians gave their written informed consent, and children agreed to participate. \autoref{tab:overview-ds} gives an overview of the datasets used in the respective \hyperref[results:paperI]{Research Article \uproman{1}} to \hyperref[results:paperIV]{\uproman{4}} presented in \chapref{chap:results}.

\subsection{Dataset \uproman{1}}
\label{methods:datasets:I}
Dataset \uproman{1} was collected in one of the experiments conducted in the context of the Bremen-Hand-Study@Jacobs, which investigated the influence of age and expertise on manual dexterity over the working life \cite{Voelcker-Rehage2013}. This study was in accordance with the Declaration of Helsinki and approved by the Ethics Committee of the German Psychological Society. The dataset was analyzed in \hyperref[results:paperI]{Research Article \uproman{1}} and \hyperref[results:paperIV]{\uproman{4}}. 

\subsubsection{Participants}
\label{methods:datasets:I:participants}
There are recordings of 59 participants with valid \gls{eeg} measurements in the dataset. Based on their age and profession, each participant is labeled as a young novice, early middle-aged novice, early middle-aged expert, late middle-aged novice, or late middle-aged expert. The group of novices comprised professional profiles whose daily routine did not require fine motor control of the hands, such as service workers, insurance agents, office workers, and students. Experts, on the other hand, referred to persons with more than ten years of professional experience in a job with pronounced fine motor requirements for hand control, such as opticians, goldsmiths, dentists, dental technicians, or hearing aid technicians \cite{Ericsson1991}. In \hyperref[results:paperI]{Research Article \uproman{1}}, only the young (n~=~13, age: 18 to 25~years) and late middle-aged (n~=~13, age: 55 to 65~years) novices were considered. In \hyperref[results:paperIV]{Research Article \uproman{4}} all early and late middle-aged experts (n~=~22, age: 34 to 65~years), as well as all early and late middle-aged novices (n~=~21, age: 35 to 64~years), were included in the analyses\footnote{Due to incorrect trigger position and insufficient data quality five participants of the initial sample were excluded.}.

\subsubsection{Experimental Procedures}
\label{methods:datasets:I:experiment}
The experiment conducted was a force-tracking experiment (see \autoref{fig:DSI_exp1} and \hyperref[pub:paperI]{Published Research Article \uproman{1}} and \hyperref[pub:paperII]{\uproman{2}} for experimental details). Participants held a force transducer between the thumb and index finger of their respective right and left hands. The task was to apply the correct force to track a target force line displayed on a screen as accurately as possible. A total of 160 trials were conducted. For the first 40 trials, a steady line and the following 40 trials, a sinusoidal line had to be followed both with the right hand. This sequence, i.e., 40 times steady and 40 times sinusoidal force tracking, was then repeated with the left hand.\\
Grip force and \gls{eeg} were recorded. Before the experiments, resting \glspl{eeg} with eyes open and eyes closed were recorded for 30~s each while participants sat comfortably on a chair.

\begin{figure}[ht]
\begin{center}
\input{figures/paradigma_1.pdf_tex}
\captionsetup{justification=justified}
\caption[Schematic presentation of the force-tracking task conducted in Dataset \uproman{1}]{Schematic presentation of the force-tracking task conducted in Dataset \uproman{1}. The task was to apply the correct force to a force transducer using a precision grip with the right or left hand to track a target force level (green line) as precisely as possible. Participants received feedback, i.e., they saw their applied force (yellow line).}
\label{fig:DSI_exp1}
\end{center}
\end{figure}

\newpage
\subsection{Dataset \uproman{2}}
\label{methods:datasets:II}
Dataset \uproman{2} contains recordings from three experimental studies, each focusing on a different age group and referred to below as Study 1, Study 2, and Study 3.\\
Study 1 is the Bremen-Hand-Study@Jacobs presented above. Study 2, the Re-LOAD project, investigated the relationship between motor learning and cognitive function in older adults \cite{Hübner2018a, Hübner2018b}. Study 3, the CEBRIS project, investigated the influence of physical training on the cognitive functions of children \cite{Koutsandreou2016}. The German Psychological Society granted ethical approval for Studies 1 and 2 and the Ethics Committee of the Faculty of Humanities of the Saarland University, Germany, for Study 3. The dataset is described detailed in \cite{Reuter2019} and was analyzed in \hyperref[results:paperII]{Research Article \uproman{2}}.

\subsubsection{Participants}
\label{methods:datasets:II:participants}
The full dataset contains recordings from 222 participants, including 92 participants recorded in Study 1, 81 in Study 2, and 49 in Study 3. Participants are separated into the following age categories \cite{Reuter2019}: children (n~=~46, age: 8 to 10~years), young adults (n~=~39, age: 20 to 29~years), early middle-aged adults (n~=~21, age: 36 to 48~years), late middle-aged adults (n~=~25, age: 55 to 64~years), old adults $<$75 (n~=~40, age: 66 to 75~years), very old adults $>$75 (n~=~38, age: 76 to 83~years)\setcounter{footnote}{2}\footnote{In the sample used here 13 participants were excluded due to insufficient data quality.}.

\subsubsection{Experimental Procedures}
\label{methods:datasets:II:experiment}
All participants performed a modified version of the Flanker task previously reported in \citeauthor{Reuter2017} \cite{Reuter2017}, \citeauthor{Winneke2012} \cite{Winneke2012, Winneke2019}, and summarized in \citeauthor{Reuter2019} \cite{Reuter2019} (see \autoref{fig:DSII_exp2} and \hyperref[pub:paperII]{Published Research Article \uproman{2}}). The task was to press the correct key corresponding to a central target stimulus surrounded by distracting flanker stimuli as quickly as possible. In Study 1 and Study 3, participants performed 300 trials (approx. 100 trials per stimulus), whereas, in Study 2, they performed 150 trials (approx. 50 trials per stimulus) in randomized order. Other than this, the same experimental procedures were used in all studies, including the \gls{eeg} measurements system. 

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_2.pdf_tex}
\captionsetup{justification=justified}
\caption[Schematic presentation of the flanker task conducted in Dataset \uproman{2}]{Schematic presentation of the flanker task conducted in Dataset \uproman{2}. The task was to press the correct key corresponding to a central target stimulus surrounded by distracting flanker stimuli as quickly as possible. Adapted from \citeauthor{Winneke2019} \cite{Winneke2019} with permission.}
\label{fig:DSII_exp2}
\end{center}
\end{figure}

\subsection{Dataset \uproman{3}}
\label{methods:datasets:III}
Dataset \uproman{3} was collected during an intervention study at Paderborn University in which the feasibility of learning to play golf, as well as its impact on cognitive performance and (neuro-)biological markers, was investigated \cite{Ströhlein2020,Stroehlein2021,Gowik2023}. This intervention study was registered at the German Clinical Trials Register (DRKS00014921) and approved by the Ethics Committee of the University of Muenster. The dataset is described in detail in \hyperref[pub:paperIII]{Published Research Article \uproman{3}}. 

\subsubsection{Participants}
\label{methods:datasets:III:participants}
The dataset contains recordings from 41 elderly participants. Based on their performance on a 6 min walking test, participants’ cardiorespiratory fitness was assessed in preceding appointments, and two groups were formed, a less fit (n~=~16, age: 63 to 77~years) and a fit group (n~=~15, age: 60 to 66~years).

\subsubsection{Experimental Procedures}
\label{methods:datasets:III:experiment}
Participants performed sensory, motor, and cognitive tasks, each lasting 90~s during which \gls{eeg} was recorded (see \autoref{fig:DSII_exp3}). Prior to the tasks, \gls{eeg} was recorded for four minutes in a rest condition in a supine position with eyes closed.

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_3.pdf_tex}
\captionsetup{justification=justified}
\caption[Schematic presentation of the motor, sensory and cognitive tasks conducted in Dataset \uproman{3}]{Schematic presentation of the motor, sensory and cognitive tasks conducted in Dataset \uproman{3}. The sensory task involved the stimulation of the index finger with two pin patterns of a braille device (A). The motor task was to apply the correct force to a force transducer using a precision grip with the right hand to track a target force level (blue line) as precisely as possible. Participants received feedback, i.e., they saw their applied force (red bar) (B). The cognitive task involved listening to a sequence of letters presented via two speakers behind them (C) and pressing the foot switch with the right foot if a letter appeared again two letters later (2-back).}
\label{fig:DSII_exp3}
\end{center}
\end{figure}

\paragraph{Sensory Task}
The index fingertips of the participant's left hand were stimulated with the pins of a braille device presenting two pin configurations in random order. 
\paragraph{Motor Task} 
The motor task corresponded to the force tracking experiment as described in \chapref{methods:datasets:I:experiment}. Here, the target was a line that moved from the right to the left on the screen for 90~s and changed level every 3~s in randomized order between heights representing 10~\%, 20~\% and 30~\% of participants' individual \gls{mvc}. The task was to apply the appropriate force to the force transducer to move a cursor to follow the target force level presented on a screen as closely as possible.
\paragraph{Cognitive Task}
The cognitive task was an auditory n-back task. Participants were asked to listen to a sequence of letters presented via two speakers behind them and press the foot switch with the right foot if a letter appeared again two letters later (2-back).

\begin{table}[ht]
\begin{threeparttable}
\captionsetup{justification=raggedright,singlelinecheck=false}
\caption[Overview of datasets and participants in each research article]{Overview of datasets and participants in each research article.}
\label{tab:overview-ds}
\begin{tabular}{@{}lllllcc@{}}
    \toprule
    \textbf{Research}  & \textbf{Dataset} & \textbf{\gls{eeg}-} &\textbf{Paradigm} & \multicolumn{3}{l}{\textbf{Participants}} \\
    \textbf{Article}  & & \textbf{System} & & & n & Age range [years]\\ \midrule
    \hyperref[results:paperI]{\uproman{1}} &\hyperref[methods:datasets:I]{\uproman{1}} & Biosemi: &  Force control  & Late m-a adults & 13 & 55--65 \\
     & & 32-channels & & Young adults & 13 & 18--25 \\ \midrule
    \hyperref[results:paperII]{\uproman{2}} & \hyperref[methods:datasets:II]{\uproman{2}} & Biosemi: & Flanker  & Children & 46 & 8--10 \\
     & & 32-channels & & Young adults & 39 & 20--29 \\
     & & & & Early m-a adults & 21 & 36--48 \\
     & & & & Late m-a adults  & 25 & 55--64 \\
     & & & & Old adults $>$75 & 40 & 66--75 \\
     & & & & Old adults $<$75 & 38 & 76--83 \\ \midrule
    \hyperref[results:paperIII]{\uproman{3}} & \hyperref[methods:datasets:III]{\uproman{3}} & actiCap: & N-back & Less fit & 16 & 63--77 \\
     & & 128-channels  & Tactile oddball & Fit  & 15 & 60--66 \\
     & & & Force control  &  & \\\midrule
    \hyperref[results:paperIV]{\uproman{4}} & \hyperref[methods:datasets:I]{\uproman{1}} & Biosemi: & Force control  & Experts & 22 & 34--65 \\
     & & 32-channels & & Novices & 21 & 35--64 \\ \bottomrule
\end{tabular}
\begin{tablenotes}
  \small
  \item m-a: middle-aged
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Electroencephalography: Recording and Preprocessing}
The \gls{eeg} in \hyperref[methods:datasets:I]{Dataset \uproman{1}} and \hyperref[methods:datasets:II]{Dataset \uproman{2}} was recorded with a 32-channel Biosemi active electrode system (ActiveTwo, BioSemi, Amsterdam, Netherlands). In \hyperref[methods:datasets:III]{Dataset \uproman{3}} the \gls{eeg} was recorded with a 128-channel actiCap active electrode system (BrainProducts, Munich, Germany).\\
\\
Based on the different analysis methods, objectives, and \gls{eeg} systems, preprocessing differed slightly between the research articles. In each case, the data were down-sampled, re-referenced, and filtered. In \hyperref[results:paperI]{Research Article \uproman{1}}, \hyperref[results:paperIII]{\uproman{3}} and \hyperref[results:paperIV]{\uproman{4}}, \gls{ica} was used to reduce occular and muscle artifacts. In \hyperref[results:paperI]{Research Article \uproman{1}} and \hyperref[results:paperIV]{\uproman{4}}, trials containing large artifacts were excluded using the \textit{autoreject pipeline} \cite{Jas2017}. Due to the high number of electrodes used in \hyperref[methods:datasets:III]{Dataset \uproman{3}}, bridges were detected and interpolated based on coherence measurements and electrical distance \cite{Alschuler2014}. The exact pipelines are described in the \hyperref[pub:papers]{published research articles}.  
\newpage
\section{Machine Learning Procedures}
Applying machine learning techniques followed the state-of-the-art practices presented in \chapref{theory:ml} to enable the three approaches presented in \chapref{chap:aims_scope}. For this purpose, we used a combination of dimensionality reduction methods and classification.\\
As a preliminary step, in all approaches taken in this work, the dimensions of the \gls{eeg} data were reduced to extract specific characteristics, e.g., the network characteristics (see \autoref{fig:ML_approach} 1a). Additionally, a second level of dimensionality reduction was optionally applied. This secondary reduction served as additional feature extraction for the following analyses or facilitated the exploratory analysis performed in the third approach of this work (see \autoref{fig:ML_approach} 1b).\\
Classification procedures were used at the individual and group levels (see \autoref{fig:ML_approach} 2). At the individual level, a classification model was trained for each participant based on the \gls{eeg} data to predict which experimental condition was present, e.g., which task a participant performed. Following the first approach, this should ultimately allow inferences about dedifferentiation at the individual level and, following the second approach, provide the basis for comparing groups with different lifestyle backgrounds. In addition, following the third approach, classifiers were also trained at the group level to predict group membership and detect general patterns in the dataset. \autoref{tab:ml_methods}  summarizes the used methods for each research article. In the following, the methods will be briefly described.

\begin{figure}[ht]
\begin{center}
\input{figures/ml_approach.pdf_tex}
\captionsetup{justification=justified}
\caption[Machine learning approach used in this thesis]{Machine learning approach used in this thesis. Dimensionality reduction was used to produce a suitable representation of the \gls{eeg} data (1a). Optionally, a second level dimensionality reduction was applied to extract patterns and for visualization (1b). Finally, classification was used to classify either the task at the individual level or the group membership (2) using either the results of 1a or 1b.}
\label{fig:ML_approach}
\end{center}
\end{figure}

\begin{table}[ht]
  \begin{threeparttable}
    \captionsetup{justification=justified, singlelinecheck=false}
    \caption[Dimensionality reduction and classification methods utilized in each research article]{Dimensionality reduction and classification methods utilized in each research article.}
    \label{tab:ml_methods}
    \begin{tabular}{@{}p{3cm}p{2cm}p{2.5cm}p{2cm}p{2cm}@{}}
      \toprule
       & \multicolumn{2}{l}{\textbf{Dimensionality reduction}} & \multicolumn{2}{l}{\textbf{Classification}} \\ \cmidrule(l){2-5} 
      & Level 1a & Level 1b & Task & Group \\ \midrule
      \hyperref[results:paperI]{Research Article \uproman{1}}  & DMD & CSP & LDA & SVM \\
      \hyperref[results:paperII]{Research Article \uproman{2}}  & xDAWN & -   & SVM  & SVM \\
      \hyperref[results:paperIII]{Research Article \uproman{3}} & DMD & PCA       & -    & -    \\
      \hyperref[results:paperIV]{Research Article \uproman{4}}  & DMD & CSP, UMAP & LDA  & SVM  \\
      \bottomrule
    \end{tabular}
    \begin{tablenotes}
      \small
      \item DMD: dynamic mode decomposition, CSP: common spatial patterns, LDA: linear discriminant analysis, SVM: support vector machine, PCA: principal component analysis
    \end{tablenotes}
  \end{threeparttable}
\end{table}


\newpage
\subsection{Dimensionality Reduction}
As described above, different dimensionality reduction methods were utilized to extract a suitable representation of the EEG on the first level and further investigate this representation on the second level. The following briefly introduces the methods listed in \autoref{tab:ml_methods}.

\subsubsection{Dynamic Mode Decomposition}
To extract dynamic brain network activation patterns from the continuous \gls{eeg} activity, we chose \gls{dmd} because it can decompose the signals into spatial activation patterns (modes) that are dynamically coherent, reflecting the network nature of the underlying brain activity \cite{Brunton2016}. For the computation of \gls{dmd}, we used the \textit{exact \gls{dmd}} algorithm introduced by \citeauthor{Tu2014} \cite{Tu2014} and described and validated by \citeauthor{Brunton2016} \cite{Brunton2016} for the application to electrophysiological data. The analysis was based on the preprocessed and windowed \gls{eeg} data and \gls{dmd} modes associated with the frequency ranges $\theta$ (4 to $<$ 7~Hz), $\alpha$ (7 to $<$12~Hz), $\beta_1$ (12 to $<$16~Hz), and $\beta_2$ (16 to $<$30~Hz) were considered. We calculated the \gls{dmd} mode magnitude (absolute value) to obtain the influence of each electrode in a \gls{dmd} mode \cite{Brunton2016}.
% \Gls{dmd} was developed in the field of fluid mechanics and was applied to various fields to model time-varying dynamical systems, including neuroscience proving to extract physiological valid signal patterns \cite{Brunton2016, Kunert-Graf2019, Schmid2010, Schmid2008}. The activation patterns (modes) extracted from \gls{dmd} analysis can reveal key features such as the spatial distribution of coherent dynamics in relation to oscillation frequencies and growth or decay rates. This representation provides a deeper understanding of the functional reorganization of the brain and can serve as a starting point for further analysis \cite{Brunton2016}.\\

\subsubsection{Common Spatial Patterns}
To extract the information from the \gls{dmd} modes that would allow the best possible differentiation between the tasks, we leveraged supervised dimensionality reduction (see \chapref{theory:ml:applications_eeg}). The approach followed in this work is based on \gls{fbcsp}, a widely used algorithm for the classification of continuous tasks that extracts a weighting for each \gls{eeg} channel that maximizes the class discriminative energy for selected frequency bands \cite{Ang2012}. By multiplying these weights with the channel values, meaningful features are generated. The weightings were calculated based on \gls{dmd} magnitudes in each frequency band (see \hyperref[pub:paperI]{Published Research Article \uproman{1}} for details on the implementation).

\subsubsection{Principal Component Analysis}
\Gls{pca} aims at extracting the statistically most descriptive components from highly dimensional data \cite{BruntonKutz2019}. We used the \gls{svd} algorithm and reduced the dimension of the \gls{dmd} modes of all time windows to their main features. Therefore, we calculated a \gls{svd} over all frequency-specific modes over all time windows per participant and extracted the singular vectors and values. The singular vectors represent the principal components and capture the most significant or dominant \gls{dmd} patterns. The singular values capture the proportion of variance accounted for by this pattern. Higher singular values indicate that the associated dominant pattern captures more variation among all \gls{dmd} modes during task completion and can be considered representative of the stability or prominence of this pattern.

\subsubsection{Uniform Manifold Matrix Approximation and Projection}
While \gls{pca} was used to explain patterns of variation within a participant, we relied on \gls{umap} to capture the structure both on a local level, i.e., within a participant, and on a global level, i.e., between participants. \Gls{umap} constructs a low-dimensional representation by modeling the data as a topological manifold, considering both the distances between data points and the local density. This method is particularly effective in visualizing and exploring complex data patterns and meaningful relationships in the data \cite{Mcinnes2018}. For this, we first calculated the arithmetic mean over the \gls{dmd} modes of all windows per frequency band, trial, and participant and then applied \gls{umap} to obtain a lower-dimensional representation that captures underlying patterns and meaningful relationships in the data, facilitating visualization and exploration of \gls{dmd} patterns.

\subsubsection{xDAWN}
To process the event-related \gls{eeg} data, we utilized the xDAWN algorithm \cite{Rivet2009}. By applying the xDAWN algorithm, it is possible to obtain a set of weights that emphasize the relevant \gls{eeg} activity while suppressing noise and artifacts, leading to improved signal quality for further analysis or classification tasks. In this way, it is possible to induce activation patterns, i.e., neural responses to external stimuli at the level of individual trials. In contrast to the previous methods, we did not use \gls{dmd} first but applied xDAWN to the preprocessed trials to ensure comparability to previous \gls{erp} analyses \cite{Reuter2019}.

\subsection{Classification}
The classification was performed on a trial-by-trial basis, i.e., models were learned that can predict for each participant to which task a given trial belongs or cross-participant to which group the performing participant belongs. For model selection and evaluation, we relied on nested cross-validation (see \chapref{theory:ml:applications_eeg}). For all datasets, ten splits were used in the inner and outer cross-validation loops, keeping 80~\% of the dataset for training and 20~\% for testing. In the inner loop, hyperparameters were tuned according to a grid search procedure in which a given parameter space is provided to select the best-fitting parameters \cite{Varoquaux2017}. Consequently, one model was tested for each of the ten outer splits. The final metrics are the average over the outer splits and represent the performance of the classification algorithm. For model evaluation, we constructed confusion matrices summarizing all correct and false predicted instances of the test set \cite{Fawcett2006} (see \autoref{tab:confusion-matrix}). Additionally, we calculated the common performance metrics summarized in \autoref{tab:metrics-summary}.

\begin{table}[ht]
    \captionsetup{justification=justified, singlelinecheck=false}
    \caption[Confusion matrix]{Confusion matrix. If an actual value is positive and is classified as positive, it is a \gls{tp} result. If the positive instance is classified as negative, it is a \gls{fn} result. If an instance is actually negative and classified as negative, it is called \gls{tn}. Consequently, if an instance is negative and classified as positive, it is a \gls{fp} \cite{Fawcett2006}.}
    \label{tab:confusion-matrix}
    \renewcommand{\arraystretch}{1.25}
    \centering
        \begin{tabular}{cc|c|c|}
            \cline{3-4}
            & & \multicolumn{2}{c|}{Predicted Class} \\ \cline{3-4} 
            & & Positive & Negative \\ \hline
            \multicolumn{1}{|c|}{\multirow{2}{*}{Actual Class}} & Positive & True Positive (TP) & False Negative (FN) \\ \cline{2-4} 
            \multicolumn{1}{|c|}{} & Negative & False Positive (FP) & True Negative (TN) \\ \hline
        \end{tabular}
\end{table}

\noindent To estimate the significance of these metrics, we related them to the theoretical chance level, i.e., the metrics that would result if the class labels were randomly assigned. However, because this leads to a biased estimate of the significance of model performance when the distribution is nonuniform, and the data sets are small, we additionally determined the random level of the values using permutation procedures. This involved repeatedly shuffling the labels at random to produce a null distribution against which to test the significance of a model. For the larger data sets, however, we relied on an empirical approach and estimated the significance of the metrics by computing a binomial distribution. The appropriate method was chosen individually depending on the dataset, model objective, and distribution of classes. The results consequently mark the reference values as theoretical, analytical, or empirical chance level. A detailed justification of the chosen methods is described in the \hyperref[pub:papers]{published research articles}.

\glsunset{auc}
\begin{table}[ht]
  \begin{threeparttable}
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \caption[Summary of metrics to evaluate model performance]{Summary of metrics to evaluate model performance.}
    \label{tab:metrics-summary}
    \renewcommand{\arraystretch}{1.25}
    \begin{tabular}{@{}p{3.5cm}p{4cm}p{6.5cm}@{}}
        \toprule
        \textbf{Metric} & \multicolumn{1}{c}{\textbf{Formula}} & \multicolumn{1}{c}{\textbf{Description}}\\ 
        \midrule
            Accuracy & \centering$\displaystyle\frac{TP + TN}{TP + TN + FP + FN}$ & Measures the overall correctness of the model's predictions.\\
            Precision & \centering$\displaystyle\frac{TP}{TP + FP}$ & Measures the proportion of true positive predictions among all positive predictions.\\
            Recall (Sensitivity) & \centering$\displaystyle\frac{TP}{TP + FN}$ & Measures the proportion of true positive predictions among all actual positive samples.\\
            Specificity & \centering$\displaystyle\frac{TN}{TN + FP}$  & Measures the proportion of true negative predictions among all actual negative samples.\\
            F1 Score & \centering$\displaystyle\frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$  &  Harmonic mean of precision and recall, providing a balanced measure between the two.\\
            AUC & \centering- & Area under the receiver operating characteristic curve, which measures the performance of a binary classification model across various threshold settings. \\
        \bottomrule
    \end{tabular}
    \begin{tablenotes}
    \small
    \item \gls{tp}: true positive, \gls{tn}: true negative, \gls{fp}: false positive, \gls{fn}: false negative, \gls{auc}: area under the receiver operating characteristic curve
    \end{tablenotes}
\end{threeparttable}
\end{table}

\noindent In the research articles, we experimented with multiple algorithms based on recent literature to find the most suitable models for the respective tasks \cite{Shoorangiz2023}. In doing so, we finally used \gls{svm} and \gls{lda}, which both have a comprehensive application history to neuroscience data and are well suited to our specific problems.  \Gls{svm} is one of the most commonly used algorithms for neuroscience data \cite{Varoquaux2017}. The algorithm generates optimal decision boundaries, called hyperplanes. It can thus handle both linearly separable and non-linearly separable data by using kernel functions to map the input space into a higher-dimensional feature space \cite{Shoorangiz2023}. \Gls{lda} is specifically used in the context of \Gls{bci} and has proven to be successful in task decoding \cite{Blankertz2008}. This algorithm aims to find a linear combination of features that maximizes the separation between different classes, making it particularly effective when the classes are well-separated \cite{Shoorangiz2023}.
\newpage
\noindent All machine learning pipelines were implemented following the framework of the Python package scikit-learn \cite{Pedregosa2011}. If the methods were not implemented, they were realized using custom scripts in Python or Matlab. A detailed description of the complete analysis pipelines and details of the respective implementation can be found in the \hyperref[pub:papers]{published research articles}. 
