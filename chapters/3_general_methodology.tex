As stated previously diverse datasets containing \gls{eeg} data from individuals spanning different life stages and lifestyle backgrounds were analyzed by using methods from the field of supervised and unsupervised machine learning. Unsupervised learning was used to generate a low-dimensional representation of the EEG that can be used to gain insight and as input to supervised learning. Different age groups and groups with different lifestyle factors were considered, and tested with different paradigms, so that both task-related and resting EEG were used in the analyses. Supervised learning consequently took place at the individual level as well as at the group level. The former means that one model was trained per subject, which for each subject individually the cortical representation of the task for each subject individually and finally allows conclusions about e.g. dedifferentiation. The latter means that one model was trained for the whole group to detect general overlapping patterns in the group structure. This approach is visualized in Figure XY

\section{Datasets}
The data sets were selected from experiments in published projects in which different study paradigms were used to investigate age-related differences between age groups and groups with different lifestyle backgrounds.

\subsection{Dataset \uproman{1}}
Dataset \uproman{1} was collected as part of the Bremen Hand Study@Jacobs, which investigated the influence of age and 
expertise on hand dexterity over the working life \cite{Voelcker-Rehage2013}. Several experiments were conducted to explore tactile perception, fine motor control, and their corresponding neurophysiological correlates, as well as their trainability. This dataset specifically contains recordings from one of those experiments that assessed fine motor control using force transducers in conjunction with \gls{eeg}. 

\subsubsection{Participants}
The dataset consists of recordings from 59 participants as a subset of the Bremen-Hands-Study@Jacobs, where individuals were recruited through flyers, newspaper articles, and phone calls. Prior to inclusion, all individuals gave their informed consent to participate and completed a questionnaire, in which they reported good health, no neurological disorders, and normal or corrected-to-normal hearing and vision. Participants were identified as right-handed using the Edinburgh Handedness Inventory \cite{Oldfield1971}. In compensation, participants were paid \euro{8} per hour. The ethical principles of the Declaration of Helsinki were followed and the study was approved by the Ethics Committee of the German Psychological Society.\\
Based on their age and occupation, participants were labeled as young novice (N=xY, age=XY), middle-aged novice (N=xY, age=XY), old novice (N=xY, age=XY), middle-aged expert (N=xY, age=XY) or old expert (N=xY, age=XY). Novices were defined as occupational profiles whose daily routine does not require fine motor control of the hands, such as service personnel, insurance agents, office workers, and students. Experts, on the other hand, referred to persons with more than 10 years of professional experience in a job with pronounced fine motor requirements for hand control such as opticians, goldsmiths, dentists, dental technicians, or hearing aid technicians. This criterion was selected in accordance with \cite{Ericsson1991}. 

\subsubsection{Experimental Procedures}
blavlalalalal\\
\\
\begin{figure}[h]
\def\svgwidth{\columnwidth}
\input{figures/dedifferentiation11.pdf_tex}
\caption[The computational model proposed by Li and colleagues \cite{Li2001,Li2002}.]{The authors used a feedforward backpropagation neural network model with logistic activation function $f(z)$ and simulated altered neuromodulation by varying the gain parameter $g$ in $f(z)$ of each neuron (A). Lower $g$ values represent deficient neuromodulation and responsiveness due to aging, resulting in a dampened neuron activation (B). Simulations showed that the activation pattern of simulated neurons differs less for different stimuli, i.e., the network's hidden layer shows a less distinctive representation of the stimulus (C). The activation of a single neuron is more variable in networks with lower $g$ value, i.e., older networks, for multiple stimulations with the same stimulus (D).}
\label{fig:dedifferentiation}
\end{figure}

% To approximate the performance of a predictive model a dataset is typically divided into a training and testing set. The training set is used for learning a model whereas the testing set is used to estimate the generalization performance to new unseen data, i.e. data which was not used during the process of training. The training data can further be divided into a training and validation portion in order to compare different model types or user defined settings of a learning algorithms, so called hyperparameters. However, this three time division may drastically reduce the data size usable for training and my result in flawed generalization evaluation due to the randomness of the split. Therefore several procedures can be applied. In a simple k-fold cross-validation, for example, the training data is divided k-times. Thus each time a different subset of the data is used for validation while the rest is used for training. Usually this is repeated for a range of models and subsequent hyperparamters and the model and hyperparameter performing best on average are selected for final testing. A more advanced method denoted nested cross-validation adds a second k-fold cross-validation loop for the final model evaluation (see Figure \ref{fig1:CV} for a visual representation of the procedures).    

% \begin{figure*}[h]
%   \dummyfig{Cross-validation procedures} 
%   \caption{Cross-validation procedures}
%   \label{fig1:CV}
% \end{figure*}
