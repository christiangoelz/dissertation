\section{Datasets}
The datasets were selected from experiments in published projects in which different study paradigms were used to investigate age-related differences between age groups and groups with different lifestyle backgrounds. The following is a brief description of the datasets. All included participants gave their written informed consent. For children, guardians gave their written informed consent and children agreed to participate. \autoref{tab:overview-ds} gives an overview of which datasets were used in the respective \hyperref[results:paper1]{Research Article \uproman{1}} to \hyperref[results:paperIV]{\uproman{4}}. 

\subsection{Dataset \uproman{1}}
\label{methods:datasets:I}
Dataset \uproman{1} was collected in one of the experiments conducted in the context of the Bremen Hand Study@Jacobs, which investigated the influence of age and expertise on manual dexterity over the working life \cite{Voelcker-Rehage2013}. This study was in accordance with the Declaration of Helsinki and approved by the Ethics Committee of the German Psychological Society. The dataset was analyzed in \hyperref[paperI]{Research Article \uproman{1}} and \hyperref[paperIV]{\uproman{4}}. 

\subsubsection{Participants}
\label{methods:datasets:I:participants}
There are recordings of 59 participants in the dataset. The datasset represents a subset of the Bremen Hand Study@Jacobs and considers only participants with \gls{eeg} measurements in the respective experiment. Based on their age and occupation, each participant is labeled as a young novice, middle-aged novice, middle-aged expert, late middle-aged novice, or late middle-aged expert. The group of novices comprised occupational profiles whose daily routine did not require fine motor control of the hands, such as service workers, insurance agents, office workers, and students. Experts, on the other hand, referred to persons with more than ten years of professional experience in a job with pronounced fine motor requirements for hand control, such as opticians, goldsmiths, dentists, dental technicians, or hearing aid technicians \cite{Ericsson1991}. In \hyperref[results:paperI]{Research Article \uproman{1}}, only the young (N=13, age: 18 to 25 years) and late middle-aged (N=13, age: 55 to 65 years) novices were considered. In \hyperref[results:paperIV]{\hyperref[paperIV]{\hyperref[paperIV]{Research Article \uproman{4}}}} all middle-aged and late middle-aged experts (N=22, age: 34 to 65 years), as well as all middle-aged and late middle-aged novices (N=21, age: 35 to 64), were included in the analyses\footnote{Due to incorrect trigger position and insufficient data quality five participants of the initial sample were excluded}.

\subsubsection{Experimental Procedures}
\label{methods:datasets:I:experiment}
The experiment conducted was a force-tracking experiment (see \autoref{fig:DSI_exp1} and \hyperref[pub:paperI]{Published Research Article \uproman{1}} and \hyperref[pub:paperI]{\uproman{2}} for experimental details). Participants held a force transducer between the thumb and index finger of their respective right and left hands. The task was to apply the correct force to track a target force line displayed on a screen as accurately as possible. A total of 160 trials were conducted. For the first 40 trials, a steady line and the following 40 trials, a sinusoidal line had to be followed both with the right hand. This sequence, i.e., 40 times steady and 40 times sinusoidal force tracking, was then repeated with the left hand.\\
Grip force and \gls{eeg} were recorded. Before the experiments resting \glspl{eeg} with eyes open and eyes closed were recorded for 30 s each while participants sat comfortably on a chair.

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_1.pdf_tex}
\caption[Schematic presentation of the force-tracking task conducted in dataset \uproman{1}.]{Schematic presentation of the force-tracking task conducted in dataset \uproman{1}. The task was to apply the correct force to a force transducer using a precision grip with the right or left hand to track a target force level (green line) as precisely as possible. Participants received feedback, i.e., they saw their applied force (yellow line).}
\label{fig:DSI_exp1}
\end{center}
\end{figure}

\newpage
\subsection{Dataset \uproman{2}}
\label{methods:datasets:II}
Dataset \uproman{2} contains recordings from three experimental studies, each focusing on a different age group and referred to below as Study 1, Study 2, and Study 3.\\
Study 1 is the Bremen-Hand-Study@Jacobs presented above. Study 2, the Re-LOAD project, investigated the relationship between motor learning and cognitive function in older adults \cite{Hübner2018a, Hübner2018b}. Study 3, the CEBRIS project, investigated the influence of physical training on the cognitive functions of children \cite{Koutsandreou2016}. The German Psychological Society granted ethical approval for Study 1 and 2 and the Ethics Committee of the Faculty of Humanities of the Saarland University, Germany, for Study 3. The dataset is described detailed in \cite{Reuter2019} and was analyzed in \hyperref[res:paperII]{Research Article \uproman{2}}

\subsubsection{Participants}
\label{methods:datasets:II:participants}
The full dataset contains recordings from 222 participants, including 92 participants recorded in Study 1, 81 in Study 2, and 49 in Study 3. Participants are separated into the following age categories \cite{Reuter2019}: children (N~=~46, age: 8 to 10~years), young adults (N~=~39, age: 20 to 29~years), early middle-aged adults (N~=~21, age: 36 to 48~years), late middle-aged adults (N~=~25, age: 55 to 64~years), old adults $<$75 (N~=~40, age: 66 to 75~years), very old adults $>$75 (N~=~38, age: 76 to 83~years)\footnote{In the sample used here 13 participants were excluded due to insufficient data quality.}.

\subsubsection{Experimental Procedures}
\label{methods:datasets:II:experiment}
All participants performed a modified version of the Flanker task previously reported in \citeauthor{Reuter2017} \cite{Reuter2017}, \citeauthor{Winneke2012} \cite{Winneke2012, Winneke2019}, and summarized in \citeauthor{Reuter2019} \cite{Reuter2019} (see \autoref{fig:DSII_exp2} and \hyperref[pub:paperII]{Published Research Article \uproman{2}}). The task was to press the correct key corresponding to a central target stimulus surrounded by distracting flanker stimuli as quickly as possible. In Study 1 and Study 3, participants performed 300 trials (approx. 100 trials per stimulus), whereas, in Study 2, they performed 150 trials (approx. 50 trials per stimulus) in randomized order. Other than this, the same experimental procedures were used in all studies, including the \gls{eeg} measurements system. 

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_2.pdf_tex}
\caption[Schematic presentation of the flanker task conducted in Dataset \uproman{2}.]{Schematic presentation of the flanker task conducted in Dataset \uproman{2}. The task was to press the correct key corresponding to a central target stimulus surrounded by distracting flanker stimuli as quickly as possible. Adapted from \citeauthor{Winneke2019} \cite{Winneke2019} with permission.}
\label{fig:DSII_exp2}
\end{center}
\end{figure}

\subsection{Dataset \uproman{3}}
\label{methods:datasets:III}
Dataset \uproman{3} was collected during an intervention study at Paderborn University in which the feasibility of learning to play golf, as well as its impact on cognitive performance and on (neuro-)biological markers, was investigated \cite{Ströhlein2020,Stroehlein2021,Gowik2023}. This intervention study was registered at the German Clinical Trials Register (DRKS00014921) and approved by by the Ethics Committee of the University of Muenster. The dataset is described in detail in \hyperref[pub:paperIII]{Published Research Article \uproman{3}}. 

\subsubsection{Participants}
\label{methods:datasets:III:participants}
The dataset contains recordings from 41 elderly participants. Based on their performance on a 6 min walking test participants’ cardiorespiratory fitness was assessed in preceding appointments and two groups were formed, a less fit (N=16, age: 63 to 77 years) and a fit group (N=15, age: 60 to 66 years).

\subsubsection{Experimental Procedures}
\label{methods:datasets:II:experiment}
Participants performed sensory, motor, and cognitive tasks each lasting 90 s during which \gls{eeg} was recorded (see \autoref{fig:DSII_exp3}) Prior to the tasks, \gls{eeg} was recorded for four minutes in a rest condition in a supine position with eyes closed.

\begin{figure}[h]
\begin{center}
\input{figures/paradigma_3.pdf_tex}
\caption[Schematic presentation of the motor, sensory and cognitive tasks conducted in Dataset \uproman{3}.]{Schematic presentation of the motor, sensory and cognitive tasks conducted in Dataset \uproman{3}. The sensory task involved the stimulation of the index finger with two pin patterns of a braille device (A). The motor task was to apply the correct force to a force transducer using a precision grip with the right hand to track a target force level (blue line) as precisely as possible. Participants received feedback, i.e., they saw their applied force (red bar) (B). The cognitive task involved listening to a sequence of letters presented via two speakers behind them (C) and pressing the foot switch with the right foot if a letter appeared again two letters later (2-back).}
\label{fig:DSII_exp3}
\end{center}
\end{figure}

\paragraph{Sensory task}
The index fingertips of the participant's left hand were stimulated with the pins of a braille device presenting two pin configurations in random order. 
\paragraph{Motor task} 
The motor task corresponded to the force tracking experiment as described in \chapref{methods:datasets:I:experiment}. Here, the target was a line that moved from the right to the left on the screen for 90 s and changed level every 3 s in randomized order between heights representing 10\%, 20\% and 30\% of participants' individual \gls{mvc}. The task was to apply the appropriate force to the force transducer to move a cursor so that it followed the target force level presented on a screen as closely as possible.
\paragraph{Cognitive task}
The cognitive task was an auditory n-back task. Participants were asked to listen to a sequence of letters presented via two speakers behind them and press the foot switch with the right foot if a letter appeared again two letters later (2-back).

\begin{table}[ht]
\captionsetup{justification=raggedright,singlelinecheck=false}
\caption{Overview of datasets and participants in each research article.}
\label{tab:overview-ds}
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{Research}  & \textbf{Dataset} & \textbf{\gls{eeg}-} &\textbf{Paradigm} & \multicolumn{2}{l}{\textbf{Participants}} \\
\textbf{Article}  & & \textbf{System} & & \\ \midrule
\hyperref[res:paperI]{\uproman{1}} &\hyperref[methods:datasets:I]{\uproman{1}} & Biosemi: &  Force Control  & Late m-a adults & N=13, age: 55 to 65 years \\
 & & 32-channels & & Young adults & N=13, age: 18 to 25 years \\ \midrule
\hyperref[res:paperII]{\uproman{2}} & \hyperref[methods:datasets:II]{\uproman{2}} & Biosemi & Flanker  & Children & N=46, age: 8 to 10 years  \\
 & & 32-channels & & Young adults & N=39, age: 20 to 29 years \\
 & & & & Early m-a adults & N=21, age: 36 to 48 years \\
 & & & & Late m-a adults  & N=25, age: 55 to 64 years \\
 & & & & Old adults $>$75 & N=40, age: 66 to 75 years \\
 & & & & Old adults $<$75 & N=38, age: 76 to 83 years \\ \midrule
\hyperref[res:paperIII]{\uproman{3}} & \hyperref[methods:datasets:III]{\uproman{3}} & actiCap: & Nback & Low fit & N=16, age: 63 to 77 years \\
 & & 128-channels  & Tactile Oddball & Fit  & N=15, age: 60 to 66 years \\
 & & & Force Control  &  & \\\midrule
\hyperref[res:paperIV]{\uproman{4}} & \hyperref[methods:datasets:I]{\uproman{1}} & Biosemi: & Force Control  & Experts & N=22, age: 34 to 65 years \\
 & & 32-channels & & Novices & N=21, age: 35 to  64 years \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Electroencephalography: Recording and Preprocessing}
The \glspl{eeg} in Dataset \chapref{methods:datasets:I} and \chapref{methods:datasets:II} were recorded with a 32-channel Biosemi active electrode system (ActiveTwo, BioSemi, Amsterdam, Netherlands). In \chapref{methods:datasets:III} \gls{eeg} measurements were recorded with a 128-channel actiCap active electrode system (BrainProducts, Munich, Germany).\\
\\
Based on the different analysis methods, objectives, and \gls{eeg} systems used, the preprocessing differed slightly between the research articles. In each case, the data were down-sampled, re-referenced, and filtered. In \hyperref[res:paperI]{Research Article \uproman{1}}, \hyperref[res:paperIII]{\uproman{3}} and \hyperref[res:paperIV]{\uproman{4}}, ICA was used to reduce occular and muscle artifacts. In \hyperref[res:paperI]{Research Article \uproman{1}} and \hyperref[res:paperIV]{\uproman{4}}, trials containing large artifacts were excluded using the \textit{autoreject pipeline} \cite{Jas2017}. Due to the high number of electrodes used in \hyperref[methods:datasets:III]{Dataset \uproman{3}}, bridges were detected and interpolated based on coherence measurements and electrical distance \cite{Alschuler2014}. The exact pipelines are described in the \hyperref[pub:papers]{published research articles}.  

\section{Machine learning procedures} 
Following state of the art approaches (see \chapref{theory:ml:applications_aging}) we used a combination of dimensionality reduction methods and classification. Dimensionality reduction was used at the first level to extract a suitable representation of the EEG data for the following classification, i.e. for feature extraction (see \autoref{fig:ML_approach} 1a), and at the second level to detect and visualize patterns in the data sets (see \autoref{fig:ML_approach} 1b). Classification procedures were used both at the individual level as well as at the group level (see \autoref{fig:ML_approach} 2). The former means that one model per participant was trained, which represents the cortical representation of an experimental condition, e.g., a task, and finally allows conclusions, e.g., about the dedifferentiation of cortical processes at the individual level. The latter means that a model was trained for the whole group to detect general overlapping patterns in the group structure. The selection of a suitable method was based on the dataset, i.e. data structure and experimental conditions, and the aim of the analysis. \autoref{tab:ml_methods}  summarizes the used methods for each research article. In the following, the methods will be briefly described.

\begin{figure}[h]
\begin{center}
\input{figures/ml_approach.pdf_tex}
\caption[Machine learning approach used in this thesis]{Machine learning approach used in this thesis. Dimensionality reduction was used to produce a suitable representation of the \gls{eeg} data (1a). Optionally a second level dimensionality reduction was applied to extract patterns and for visualization (1b). Finally, Classification was used to classify either the task at the individual level or the group membership (2) using either the results of 1a or 1b.}
\label{fig:ML_approach}
\end{center}
\end{figure}

\begin{table}[ht]
  \begin{threeparttable}
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \caption{Dimensionality reduction and classification methods utilized in each research article}
    \label{tab:ml_methods}
    \begin{tabular}{@{}p{3cm}p{2cm}p{2.5cm}p{2cm}p{2cm}@{}}
      \toprule
       & \multicolumn{2}{l}{\textbf{Dimensionality Reduction}} & \multicolumn{2}{l}{\textbf{Classification}} \\ \cmidrule(l){2-5} 
      & level 1a & level 1b & Task & Group \\ \midrule
      \hyperref[res:paperI]{Research Article \uproman{1}}  & DMD & CSP & LDA & SVM \\
      \hyperref[res:paperII]{Research Article \uproman{2}}  & xDAWN & -   & SVM  & SVM \\
      \hyperref[res:paperIII]{Research Article \uproman{3}} & DMD & PCA       & -    & -    \\
      \hyperref[res:paperIV]{Research Article \uproman{4}}  & DMD & CSP, UMAP & LDA  & SVM  \\
      \bottomrule
    \end{tabular}
    \begin{tablenotes}
      \small
      \item DMD: dynamic mode decomposition, CSP: common spatial patterns, LDA: linear discriminant analysis, SVM: support vector machine, PCA: principal component analysis
    \end{tablenotes}
  \end{threeparttable}
\end{table}


\newpage
\subsection{Dimensionality reduction}
As described above, different dimensionality reductions were performed with the aim to extract a suitable representation of the EEG on the first level and to further investigate this representation on the second level. In the following, the methods listed in \autoref{tab:ml_methods} are briefly introduced. 

\subsubsection{Dynamic mode decomposition}
To extract a relevant representation of the continuous \gls{eeg} activity, we chose \gls{dmd} because it is able to decompose the signals into spatial activation patterns that are dynamically coherent, reflecting the network nature of the underlying brain activity \cite{Brunton2016}. \Gls{dmd} was developed in the field of fluid mechanics and was applied to various fields to model time-varying dynamical systems, including neuroscience proving to extract physiological valid signal patterns \cite{Brunton2016, Kunert-Graf2019, Schmid2010, Schmid2008}. The activation patterns (modes) extracted from \gls{dmd} analysis can reveal key features such as the spatial distribution of coherent dynamics in relation to oscillation frequencies and rates of growth or decay. This provides a deeper understanding of the functional reorganization of the brain and can serve as a starting point for further analysis \cite{Brunton2016}.\\
For the computation of \gls{dmd}, we used the \textit{exact \gls{dmd}} algorithm introduced by \citeauthor{Tu2014} \cite{Tu2014} and described in \cite{Brunton2016} as applied to electrophysiological data. The analysis was based on the preprocessed and windowed \gls{eeg} data and \gls{dmd} modes associated with the frequency ranges $\theta$ (4 to $<$ 7 Hz), $\alpha$ (7 to $<$ 12 Hz), $\beta_1$ (12 to $<$ 16 Hz), and $\beta_2$ (16 to $<$ 30 Hz) were considered. We calculated the \gls{dmd} mode magnitude (absolute value) to obtain the influence of each electrode in a \gls{dmd} mode representing spatially coherent activation \cite{Brunton2016}.

\subsubsection{Common spatial patterns}
To extract the information from the \gls{dmd} modes that would allow the best possible differentiation between the tasks, we leveraged supervised dimensionality reduction (see \chapref{theory:ml:applications_eeg}). This approach is based on \gls{fbcsp}, a widely used algorithm for the classification of continuous tasks that extracts a weighting for each \gls{eeg} channel that maximizes the class discriminative energy for selected frequency bands \cite{Ang2012}. By multiplying these weights with the channel values, meaningful features are generated. The weightings were calculated based on \gls{dmd} magnitudes in each frequency band (see \hyperref[pup:paperI]{Publisshed Research Article \uproman{1}} for details on the implementation).

\subsubsection{Principal component analysis}
\Gls{pca} aims at extracting the statistically most descriptive components from highly dimensional data \cite{BruntonKutz2019}. We used the \gls{svd} algorithm and reduced the dimension of the \gls{dmd} modes of all time windows to their main features. We therefore calculated a \gls{svd} over all frequency-specific modes over all time windows per participant and extracted the singular vectors and singular values. The singular vectors represent the principal components and capture the most significant or dominant \gls{dmd} patterns, while the singular values capture the proportion of variance accounted for by this pattern. Higher singular values indicate that the associated dominant pattern captures more variation among all \gls{dmd} modes during task completion and can be considered representative of the stability or prominence of this pattern.

\subsubsection{Uniform manifold matrix approximation and projection}
While \gls{pca} was used to explain patterns of variation within a participant, we relied on \gls{umap} to capture the structure both on a local level, i.e., within a participant, and on a global level, i.e., between participants. \Gls{umap} constructs a low-dimensional representation by modeling the data as a topological manifold, considering both the distances between data points and the local density and is particularly effective in visualizing and exploring complex data patterns and meaningful relationships in the data \cite{Mcinnes2018}. For this, we first calculated the arithmetic mean over the \gls{dmd} modes of all windows per frequency band, trial, and participant and then applied \gls{umap} to obtain a lower-dimensional representation that captures underlying patterns and meaningful relationships in the data, facilitating visualization and exploration of \gls{dmd} patterns.

\subsubsection{xDAWN}
To process the event-related \gls{eeg} data, we utilized the xDAWN algorithm \cite{Rivet2009}. By applying the xDAWN algorithm, it is possible to obtain a set of weights that emphasize the relevant \gls{eeg} activity while suppressing noise and artifacts, leading to improved signal quality for further analysis or classification tasks. In this way, it is possible to induce activation patterns, i.e., neural responses to external stimuli at the level of individual trials. In contrast to the previous methods, we did not use \gls{dmd} first but applied xDAWN to the preprocessed trials as originally described to ensure comparability to previous \gls{erp} analyses \cite{Reuter2019}.


\subsection{Classification}
The classification was performed on a trial-by-trial basis, i.e., models were learned that can predict for each participant to which task a given trial belongs or cross-participant to which group the performing participant belongs. Typically, different classification algorithms and their parameters are selected, trained on one portion of the data, the so-called training data, and then tested for their performance on data not used for training, the so-called testing data \cite{Daumé2017}. The training data can further be divided into a training and validation portion to compare different model types or user-defined learning algorithm settings, so-called hyperparameters. Finally, the best model configuration is tested for its predictive performance on the test data and reported. However, this three-time division may drastically reduce the data size usable for training and may result in flawed generalization evaluation due to the randomness of the split \cite{Varoquaux2017}. Therefore several procedures can be applied. In simple k-fold cross-validation, for example, the training data is divided k-times. Thus each time, a different subset of the data is used for validation while the rest is used for training. Usually, this is repeated for a range of models and subsequent hyperparameters, and the model and hyperparameter performing best on average are selected for final testing. We used a more advanced method denoted nested cross-validation, which adds a second cross-validation loop for the final model evaluation (see Figure \ref{fig:CV} for a visual representation of the procedure).

\begin{figure*}[h]
\centering
  \input{figures/nested_cv.pdf_tex} 
  \caption[Exemplary nested cross-validation procedure.]{Exemplary nested cross-validation procedure. K-fold cross-validation is used in an outer loop for testing the best configuration tuned in an inner cross-validation loop. CV: cross-validation, Val: Validation}
  \label{fig:CV}
\end{figure*}

\noindent For all datasets, ten splits were used in the inner and outer cross-validation loops, keeping 80~\% of the dataset for training and 20~\% for testing. In the inner loop, hyperparameters were tuned according to a grid search procedure in which a given parameter space is provided to select the best-fitting parameters \cite{Varoquaux2017} comprehensively. Consequently, one model was tested for each of the ten outer splits. The final metrics are the average over the outer splits and represent the performance of the classification algorithm. For classifiers, these can be derived using a so-called confusion matrix (\autoref{tab:confusion-matrix}), which summarizes all correct and false predicted instances of the test set \cite{Fawcett2006}.  

\begin{table}[ht]
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \caption{Confusion Matrix}
    \label{tab:confusion-matrix}
    \renewcommand{\arraystretch}{1.25}
    \centering
        \begin{tabular}{cc|c|c|}
            \cline{3-4}
            & & \multicolumn{2}{c|}{Predicted Class} \\ \cline{3-4} 
            & & Positive & Negative \\ \hline
            \multicolumn{1}{|c|}{\multirow{2}{*}{Actual Class}} & Positive & True Positive (TP) & False Negative (FN) \\ \cline{2-4} 
            \multicolumn{1}{|c|}{} & Negative & False Positive (FP) & True Negative (TN) \\ \hline
        \end{tabular}
\end{table}

\noindent If an actual value is positive and is classified as positive, it is a \gls{tp} result. If the positive instance is classified as negative, it is a \gls{fn} result. If an instance is actually negative and classified as negative, it is called \gls{tn}. Consequently, if an instance is negative and classified as positive, it is a \gls{fp} \cite{Fawcett2006}. This forms the basis for various metrics reported in the research articles. \autoref{tab:metrics-summary} summarizes the metrics and their meaning.

\begin{table}[ht]
  \begin{threeparttable}
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \caption{Summary of metrics to evaluate model performance}
    \label{tab:metrics-summary}
    \renewcommand{\arraystretch}{1.25}
    \begin{tabular}{@{}p{3.5cm}p{4cm}p{6.5cm}@{}}
        \toprule
        \textbf{Metric} & \multicolumn{1}{c}{\textbf{Formula}} & \multicolumn{1}{c}{\textbf{Description}}\\ 
        \midrule
            Accuracy & \centering$\displaystyle\frac{TP + TN}{TP + TN + FP + FN}$ & Measures the overall correctness of the model's predictions.\\
            Precision & \centering$\displaystyle\frac{TP}{TP + FP}$ & Measures the proportion of true positive predictions among all positive predictions.\\
            Recall (Sensitivity) & \centering$\displaystyle\frac{TP}{TP + FN}$ & Measures the proportion of true positive predictions among all actual positive samples.\\
            Specificity & \centering$\displaystyle\frac{TN}{TN + FP}$  & Measures the proportion of true negative predictions among all actual negative samples.\\
            F1 Score & \centering$\displaystyle\frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$  &  Harmonic mean of precision and recall, providing a balanced measure between the two.\\
            AUC & \centering- & Area under the receiver operating characteristic curve, which measures the performance of a binary classification model across various threshold settings. \\
        \bottomrule
    \end{tabular}
    \begin{tablenotes}
    \small
    \item TP: true positive, TN: true negative, FP: false positive, FN: false negative, AUC: area under the receiver operating characteristic curve
    \end{tablenotes}
\end{threeparttable}
\end{table}

\noindent These values, can be related to the theoretical chance level of the values that would occur if the class labels were randomly assigned. However, since this gives a biased estimate of the significance of model performance when the distribution is uneven and the data sets are small, the random level of the values can be determined by permutation procedures, in which the labels are randomly shuffled repeatedly (e.g., 1000 times) to produce a null distribution against which the significance of a model can be tested. This analytical approach is computationally expensive. An alternative is to empirically determine a model's significance by computing a binomial cumulative distribution to estimate the significance threshold \cite{Combrisson2015}. To evaluate the validity of the trained models in the present work, the appropriate method was chosen individually depending on the data set, model objective, and distribution of classes. The results consequently mark the reference values as theoretical, analytical, or empirical chance level. A detailed justification of the chosen methods is described in the \hyperref[pub:papers]{published research articles}.\\
\\
In the research articles, we experimented with multiple algorithms based on recent literature to find the most suitable models for the respective tasks \cite{Shoorangiz2023}. In doing so, we used \gls{svm} and \gls{lda}, which both have a comprehensive application history to neuroscience data and are well suited to our specific problems.  \Glspl{svm} is one of the most commonly used algorithms for neuroscience data \cite{Varoquaux2017}. The algorithm generates optimal decision boundaries, called hyperplanes. It can thus handle both linearly separable and non-linearly separable data by using kernel functions to map the input space into a higher-dimensional feature space \cite{Shoorangiz2023}. \Gls{lda} is specifically used in the context of \Gls{bci} and has proven to be successful in task decoding \cite{Blankertz2008}. This algorithm aims to find a linear combination of features that maximizes the separation between different classes, making it particularly effective when the classes are well-separated \cite{Shoorangiz2023}.\\
\\
All machine learning pipelines were implemented following the framework of the Python package scikit-learn \cite{Pedregosa2011}. If the methods were not implemented, they were implemented by using custom scripts implemented in Python or Matlab. A detailed description of the complete analysis pipelines and details of the respective implementation can be found in the \hyperref[pub:papers]{published research articles}. 

